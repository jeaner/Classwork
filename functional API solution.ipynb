{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API\n",
    "In this module, we will explore Keras's another model building API called functional API.\n",
    "Here is the documentation: https://keras.io/getting-started/functional-api-guide/\n",
    "\n",
    "In `Sequential`, you build a model by adding a layer to the `model` object:\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, input_shape=(32,32,3), activation='relu))\n",
    "model.add(Cond2D(32, 3))\n",
    "model.add(Activation('relu'))\n",
    "...\n",
    "```\n",
    "However, in functional API, you pass the featuremap as an input to the layer:   \n",
    "\n",
    "```python\n",
    "inputs = Input(shape=(32,32,3))\n",
    "conv1 = Conv2D(32,3, activation='relu')(inputs)\n",
    "conv2 = Conv2D(32,3)(conv1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "...\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "You may have noticed that the functional API model needs a separate layer for input and output. Input() creates the the input tensor. Model() actually makes a model object from the output tensor. \n",
    "\n",
    "An advantage of functional API over Sequential is its flexibility. You can build a model architecture that has parallel paths or merging layers.\n",
    "\n",
    "```python\n",
    "...\n",
    "conv1 = Conv2D(32,3,activation='relu')(conv0)\n",
    "conv2 = Conv2D(32,5,activation='relu')(conv0)\n",
    "...\n",
    "```\n",
    "Above example shows that the feature map from conv0 is split into two paths and are passed to conv1, and conv2   \n",
    "```\n",
    "         ____ conv1 (3x3)\n",
    "        /     \n",
    "conv0---     \n",
    "        \\____ conv2 (5x5)\n",
    "```         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an inception module from scratch\n",
    "In the following exercise, you will make an inception module.\n",
    "You'll need some info from [this paper](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwiC3sb8krbaAhWK5oMKHUroAlYQFggpMAA&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1409.4842&usg=AOvVaw3v1ON5KCX99lZhuMLtNROq) to complete following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (60000, 28, 28) size: 47,040,000\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('Train Images shape: {} size: {:,}'.format(X_train.shape, X_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "Train Images shape: (60000, 28, 28, 1) size: 47,040,000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "K.set_image_dim_ordering( 'tf' )\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 123\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channel]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype( 'float32' )\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype( 'float32' )\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "print(y_test.shape)\n",
    "print('Train Images shape: {} size: {:,}'.format(X_train.shape, X_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR TURN\n",
    "## make an inception module as shown in the paper Fig 2(a), the naive version \n",
    "## each conv takes 32 filters, and has same padding, relu activation\n",
    "## Hint: use the Concatenate as in the import layers above\n",
    "## Hint: MaxPoolng2D needs 1x1 strides and same padding to match the spatial dimension\n",
    "\n",
    "def inception1(x, n = 32):\n",
    "    p1 = Conv2D(n, 1, activation ='relu', padding='same')(x)\n",
    "    p2 = Conv2D(n, 3, activation ='relu', padding='same')(x)\n",
    "    p3 = Conv2D(n, 5, activation ='relu', padding='same')(x)\n",
    "    p4 = MaxPooling2D((3,3), strides=(1, 1), padding='same')(x)\n",
    "    c =  Concatenate(axis=-1)([p1,p2,p3,p4])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR TURN\n",
    "## make an inception module as shown in the paper Fig 2(b), which has 1x1 conv layers \n",
    "## each conv takes 32 filters, and has same padding\n",
    "def inception2(x, n = 32):\n",
    "    p1 = Conv2D(n, 1, activation ='relu', padding='same')(x)\n",
    "    p2 = Conv2D(n, 1, activation ='relu', padding='same')(x)\n",
    "    p2 = Conv2D(n, 3, activation ='relu', padding='same')(p2)\n",
    "    p3 = Conv2D(n, 1, activation ='relu', padding='same')(x)\n",
    "    p3 = Conv2D(n, 5, activation ='relu', padding='same')(p3)\n",
    "    p4 = MaxPooling2D((3,3), strides=(1, 1), padding='same')(x)\n",
    "    p4 = Conv2D(n, 1, activation ='relu', padding='same')(p4)\n",
    "    c =  Concatenate(axis=-1)([p1,p2,p3,p4])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR TURN\n",
    "## Now, build a model that has this structure:\n",
    "## input-inception1-maxpool(2x2)-inception1-maxpool(2x2)-dense(128)-output\n",
    "## print out the model summary\n",
    "## Hint: input layer needs Input() as imported above\n",
    "def model1():\n",
    "    inputs = Input(X_train.shape[1:])\n",
    "    i1 = inception1(inputs)\n",
    "    mp1 = MaxPooling2D((2,2))(i1)\n",
    "    i2 = inception1(mp1)\n",
    "    mp2 = MaxPooling2D((2,2))(i2) \n",
    "    f = Flatten()(mp2)\n",
    "    d = Dense(128, activation='relu')(f)\n",
    "    out = Dense(10, activation='softmax')(d)\n",
    "    model = Model(inputs, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 32)   64          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 32)   320         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 32)   832         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 28, 28, 1)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 28, 28, 97)   0           conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 14, 14, 97)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 14, 14, 32)   3136        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 14, 14, 32)   27968       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 32)   77632       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 14, 14, 97)   0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 14, 14, 193)  0           conv2d_22[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 7, 7, 193)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 9457)         0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          1210624     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           1290        dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,321,866\n",
      "Trainable params: 1,321,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = model1()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR TURN\n",
    "## Now, build a model that has this structure:\n",
    "## input-inception2-maxpool(2x2)-inception2-maxpool(2x2)-dense(128)-output\n",
    "## name the model variable as model1\n",
    "## print out the model summary\n",
    "## Hint: input layer needs Input() as imported above\n",
    "def model2():\n",
    "    inputs = Input(X_train.shape[1:])\n",
    "    i1 = inception2(inputs)\n",
    "    mp1 = MaxPooling2D((2,2))(i1)\n",
    "    i2 = inception2(mp1)\n",
    "    mp2 = MaxPooling2D((2,2))(i2) \n",
    "    f = Flatten()(mp2)\n",
    "    d = Dense(128, activation='relu')(f)\n",
    "    out = Dense(10, activation='softmax')(d)\n",
    "    model = Model(inputs, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 28, 28, 32)   64          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 28, 28, 32)   64          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 28, 28, 1)    0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 28, 28, 32)   64          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 28, 28, 32)   9248        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 28, 28, 32)   25632       conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 28, 28, 32)   64          max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 28, 28, 128)  0           conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 14, 14, 128)  0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 32)   4128        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 32)   4128        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 14, 14, 128)  0           max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 32)   4128        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 32)   9248        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 32)   25632       conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 32)   4128        max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 14, 14, 128)  0           conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 7, 7, 128)    0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 6272)         0           max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          802944      flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           1290        dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 890,762\n",
      "Trainable params: 890,762\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = model2()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.\n",
    "What is the number of parameters from model1()    \n",
    "1,321,866    \n",
    "What is the number of parameters from model2()    \n",
    "890,762   \n",
    "Explain why and which model is more efficient.    \n",
    "model2 is more efficient because it uses 1x1 convolution layers to control the depth.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. \n",
    "Add Adam optimizer with lr=0.001. Train for 50 epochs.\n",
    "Compare the error rate for two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 0.2146 - acc: 0.9342 - val_loss: 0.0722 - val_acc: 0.9777\n",
      "Epoch 2/50\n",
      " - 6s - loss: 0.0556 - acc: 0.9829 - val_loss: 0.0641 - val_acc: 0.9813\n",
      "Epoch 3/50\n",
      " - 6s - loss: 0.0379 - acc: 0.9882 - val_loss: 0.0435 - val_acc: 0.9858\n",
      "Epoch 4/50\n",
      " - 6s - loss: 0.0295 - acc: 0.9906 - val_loss: 0.0346 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      " - 6s - loss: 0.0233 - acc: 0.9926 - val_loss: 0.0444 - val_acc: 0.9863\n",
      "Epoch 6/50\n",
      " - 6s - loss: 0.0172 - acc: 0.9942 - val_loss: 0.0475 - val_acc: 0.9869\n",
      "Epoch 7/50\n",
      " - 6s - loss: 0.0143 - acc: 0.9950 - val_loss: 0.0346 - val_acc: 0.9901\n",
      "Epoch 8/50\n",
      " - 6s - loss: 0.0144 - acc: 0.9950 - val_loss: 0.0620 - val_acc: 0.9818\n",
      "Epoch 9/50\n",
      " - 6s - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0308 - val_acc: 0.9908\n",
      "Epoch 10/50\n",
      " - 6s - loss: 0.0092 - acc: 0.9969 - val_loss: 0.0356 - val_acc: 0.9903\n",
      "Epoch 11/50\n",
      " - 6s - loss: 0.0072 - acc: 0.9977 - val_loss: 0.0393 - val_acc: 0.9898\n",
      "Epoch 12/50\n",
      " - 6s - loss: 0.0066 - acc: 0.9974 - val_loss: 0.0373 - val_acc: 0.9907\n",
      "Epoch 13/50\n",
      " - 6s - loss: 0.0083 - acc: 0.9970 - val_loss: 0.0359 - val_acc: 0.9906\n",
      "Epoch 14/50\n",
      " - 6s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0423 - val_acc: 0.9903\n",
      "Epoch 15/50\n",
      " - 6s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0417 - val_acc: 0.9905\n",
      "Epoch 16/50\n",
      " - 6s - loss: 0.0049 - acc: 0.9982 - val_loss: 0.0361 - val_acc: 0.9911\n",
      "Epoch 17/50\n",
      " - 6s - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0382 - val_acc: 0.9910\n",
      "Epoch 18/50\n",
      " - 7s - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0441 - val_acc: 0.9899\n",
      "Epoch 19/50\n",
      " - 6s - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0378 - val_acc: 0.9904\n",
      "Epoch 20/50\n",
      " - 6s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0456 - val_acc: 0.9908\n",
      "Epoch 21/50\n",
      " - 7s - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0335 - val_acc: 0.9916\n",
      "Epoch 22/50\n",
      " - 7s - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0450 - val_acc: 0.9917\n",
      "Epoch 23/50\n",
      " - 6s - loss: 0.0077 - acc: 0.9976 - val_loss: 0.0442 - val_acc: 0.9912\n",
      "Epoch 24/50\n",
      " - 6s - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0479 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      " - 7s - loss: 0.0065 - acc: 0.9976 - val_loss: 0.0380 - val_acc: 0.9926\n",
      "Epoch 26/50\n",
      " - 7s - loss: 3.6739e-04 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9915\n",
      "Epoch 27/50\n",
      " - 6s - loss: 1.3444e-04 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9933\n",
      "Epoch 28/50\n",
      " - 6s - loss: 3.6322e-05 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 0.9935\n",
      "Epoch 29/50\n",
      " - 6s - loss: 2.1804e-05 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9936\n",
      "Epoch 30/50\n",
      " - 6s - loss: 1.8472e-05 - acc: 1.0000 - val_loss: 0.0371 - val_acc: 0.9936\n",
      "Epoch 31/50\n",
      " - 7s - loss: 1.4352e-05 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 0.9935\n",
      "Epoch 32/50\n",
      " - 6s - loss: 1.2181e-05 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9934\n",
      "Epoch 33/50\n",
      " - 6s - loss: 1.0406e-05 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 0.9934\n",
      "Epoch 34/50\n",
      " - 6s - loss: 8.8356e-06 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9934\n",
      "Epoch 35/50\n",
      " - 7s - loss: 7.8676e-06 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9934\n",
      "Epoch 36/50\n",
      " - 7s - loss: 6.8723e-06 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9935\n",
      "Epoch 37/50\n",
      " - 7s - loss: 5.9571e-06 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9936\n",
      "Epoch 38/50\n",
      " - 7s - loss: 5.2064e-06 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9936\n",
      "Epoch 39/50\n",
      " - 6s - loss: 4.5523e-06 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9935\n",
      "Epoch 40/50\n",
      " - 7s - loss: 4.0536e-06 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9936\n",
      "Epoch 41/50\n",
      " - 7s - loss: 3.5883e-06 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9937\n",
      "Epoch 42/50\n",
      " - 6s - loss: 3.1359e-06 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 0.9938\n",
      "Epoch 43/50\n",
      " - 6s - loss: 2.8022e-06 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 0.9936\n",
      "Epoch 44/50\n",
      " - 6s - loss: 2.4394e-06 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9936\n",
      "Epoch 45/50\n",
      " - 6s - loss: 2.2211e-06 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 0.9937\n",
      "Epoch 46/50\n",
      " - 6s - loss: 1.9611e-06 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 0.9935\n",
      "Epoch 47/50\n",
      " - 6s - loss: 1.7401e-06 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 0.9936\n",
      "Epoch 48/50\n",
      " - 7s - loss: 1.5183e-06 - acc: 1.0000 - val_loss: 0.0430 - val_acc: 0.9935\n",
      "Epoch 49/50\n",
      " - 7s - loss: 1.3765e-06 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9934\n",
      "Epoch 50/50\n",
      " - 7s - loss: 1.2047e-06 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9934\n",
      "322.6023278236389  seconds\n",
      "CNN Error: 0.66%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb684562550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "model1.compile(loss= 'categorical_crossentropy' , optimizer= adam , metrics=[ 'accuracy' ])\n",
    "\n",
    "# Fit the model\n",
    "t0=time.time()\n",
    "log1 = model1.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=200, verbose=2)\n",
    "t1=time.time()\n",
    "print(t1-t0,\" seconds\")\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(log1.history['acc'],'b') \n",
    "plt.plot(log1.history['val_acc'],'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      " - 11s - loss: 0.2256 - acc: 0.9299 - val_loss: 0.0544 - val_acc: 0.9833\n",
      "Epoch 2/50\n",
      " - 11s - loss: 0.0473 - acc: 0.9858 - val_loss: 0.0417 - val_acc: 0.9872\n",
      "Epoch 3/50\n",
      " - 12s - loss: 0.0318 - acc: 0.9898 - val_loss: 0.0354 - val_acc: 0.9897\n",
      "Epoch 4/50\n",
      " - 12s - loss: 0.0224 - acc: 0.9928 - val_loss: 0.0341 - val_acc: 0.9896\n",
      "Epoch 5/50\n",
      " - 12s - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0325 - val_acc: 0.9891\n",
      "Epoch 6/50\n",
      " - 12s - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0330 - val_acc: 0.9903\n",
      "Epoch 7/50\n",
      " - 12s - loss: 0.0102 - acc: 0.9966 - val_loss: 0.0353 - val_acc: 0.9899\n",
      "Epoch 8/50\n",
      " - 11s - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0416 - val_acc: 0.9902\n",
      "Epoch 9/50\n",
      " - 11s - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0512 - val_acc: 0.9884\n",
      "Epoch 10/50\n",
      " - 12s - loss: 0.0073 - acc: 0.9973 - val_loss: 0.0416 - val_acc: 0.9897\n",
      "Epoch 11/50\n",
      " - 11s - loss: 0.0064 - acc: 0.9976 - val_loss: 0.0438 - val_acc: 0.9895\n",
      "Epoch 12/50\n",
      " - 12s - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0466 - val_acc: 0.9883\n",
      "Epoch 13/50\n",
      " - 12s - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0401 - val_acc: 0.9910\n",
      "Epoch 14/50\n",
      " - 11s - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0450 - val_acc: 0.9903\n",
      "Epoch 15/50\n",
      " - 11s - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0411 - val_acc: 0.9913\n",
      "Epoch 16/50\n",
      " - 11s - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0432 - val_acc: 0.9916\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0521 - val_acc: 0.9893\n",
      "Epoch 18/50\n",
      " - 12s - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0408 - val_acc: 0.9914\n",
      "Epoch 19/50\n",
      " - 11s - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0357 - val_acc: 0.9928\n",
      "Epoch 20/50\n",
      " - 11s - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0490 - val_acc: 0.9903\n",
      "Epoch 21/50\n",
      " - 11s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0548 - val_acc: 0.9889\n",
      "Epoch 22/50\n",
      " - 11s - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0414 - val_acc: 0.9922\n",
      "Epoch 23/50\n",
      " - 11s - loss: 9.5100e-04 - acc: 0.9996 - val_loss: 0.0438 - val_acc: 0.9914\n",
      "Epoch 24/50\n",
      " - 11s - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0452 - val_acc: 0.9910\n",
      "Epoch 25/50\n",
      " - 11s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0416 - val_acc: 0.9906\n",
      "Epoch 26/50\n",
      " - 11s - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0482 - val_acc: 0.9905\n",
      "Epoch 27/50\n",
      " - 11s - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0433 - val_acc: 0.9903\n",
      "Epoch 28/50\n",
      " - 11s - loss: 4.7362e-04 - acc: 0.9999 - val_loss: 0.0376 - val_acc: 0.9926\n",
      "Epoch 29/50\n",
      " - 11s - loss: 4.0342e-05 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 0.9921\n",
      "Epoch 30/50\n",
      " - 11s - loss: 1.3589e-05 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9929\n",
      "Epoch 31/50\n",
      " - 11s - loss: 6.9239e-06 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9931\n",
      "Epoch 32/50\n",
      " - 11s - loss: 5.3143e-06 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9932\n",
      "Epoch 33/50\n",
      " - 11s - loss: 4.2626e-06 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9933\n",
      "Epoch 34/50\n",
      " - 11s - loss: 3.4692e-06 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9932\n",
      "Epoch 35/50\n",
      " - 11s - loss: 2.8982e-06 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9933\n",
      "Epoch 36/50\n",
      " - 11s - loss: 2.4316e-06 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 0.9933\n",
      "Epoch 37/50\n",
      " - 11s - loss: 2.0833e-06 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9934\n",
      "Epoch 38/50\n",
      " - 11s - loss: 1.7836e-06 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9934\n",
      "Epoch 39/50\n",
      " - 11s - loss: 1.5465e-06 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9934\n",
      "Epoch 40/50\n",
      " - 11s - loss: 1.3421e-06 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9935\n",
      "Epoch 41/50\n",
      " - 11s - loss: 1.1751e-06 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 0.9935\n",
      "Epoch 42/50\n",
      " - 11s - loss: 1.0309e-06 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9934\n",
      "Epoch 43/50\n",
      " - 11s - loss: 9.1249e-07 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9935\n",
      "Epoch 44/50\n",
      " - 11s - loss: 8.0946e-07 - acc: 1.0000 - val_loss: 0.0437 - val_acc: 0.9935\n",
      "Epoch 45/50\n",
      " - 11s - loss: 7.1800e-07 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9935\n",
      "Epoch 46/50\n",
      " - 11s - loss: 6.4266e-07 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9935\n",
      "Epoch 47/50\n",
      " - 11s - loss: 5.6986e-07 - acc: 1.0000 - val_loss: 0.0441 - val_acc: 0.9935\n",
      "Epoch 48/50\n",
      " - 11s - loss: 5.0870e-07 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 0.9935\n",
      "Epoch 49/50\n",
      " - 11s - loss: 4.5841e-07 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9935\n",
      "Epoch 50/50\n",
      " - 11s - loss: 4.1373e-07 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 0.9933\n",
      "569.7058038711548  seconds\n",
      "CNN Error: 0.72%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2cVVW9x/HPj4GBAR+GBNEYEExUEBV1Lll2szQNtEBJ\nC0st1IhMsqvlFW9lWj5lds0kiQz0+vyQlBlpChpmBowxICMgD4qCDwyUojM8zczv/rH2OGdmzplz\nhjnDDHt/36/XeZ1z9l5n77UG/e511t5nbXN3REQkObp0dAVERGTXUvCLiCSMgl9EJGEU/CIiCaPg\nFxFJGAW/iEjCKPhFRBJGwS8ikjAKfhGRhOna0RVIp0+fPj5o0KCOroaIyG7jhRde2OjufXMp2ymD\nf9CgQZSVlXV0NUREdhtmtjbXshrqERFJGAW/iEjCKPhFRBJGwS8ikjAKfhGRhMka/GY2w8w2mNnS\nDOvNzG4xs1VmtsTMjk5ZN8rMVkTrLs9nxUVEZOfk0uO/AxjVwvrRwJDoMRG4DcDMCoCp0fphwFlm\nNqwtlRURkbbLeh2/u88zs0EtFBkL/J+Hezj+w8yKzWx/YBCwyt3XAJjZ/VHZl9paaZHdjTssXgyb\nNsH778N774Xn+kddXUfXUDqDPfaAyy5r//3k4wdc/YHXU96vi5alW/7RTBsxs4mEbwwMHDgwD9US\nabB1K8ybB/PnQ9eu0LNneBQVhec99oCRI6G4OP/7fvppmDIl7DsTs/zvV3Y//frtPsGfF+4+HZgO\nUFpaqjvAdxB32LwZNm4MvdNNm8Lrd9+F0aPhIx9pv/0uWwb77gt9+uRnm6tXw5//HB5PPw1btrRc\nvrAQRo2CL30JPv952HPPtu3/hRfgiivgL3+BkhK47TY47LBwkKl/7LlnOPB00WUWsgvlI/jXAwNS\n3pdEy7plWC6d0JYtcOON4fH+++nLFBXBT38KF16Yv6BasQLuvhvuuQdeeSUs69cvBOTw4Q3P/ftD\n794hKJv2jnfsgFWrwoGj/jF/flgGcNBBcP754cB1/PFQUADV1aHN1dXhsWkTPPYYPPggPPoo9OgB\np54aDgJDhjQuW//ZLl3CQWqffcKjTx/Ye294+WX4wQ/goYfC8ptuCn+zHj3y8zcTaSsLQ/NZCoUx\n/sfcfXiadacCFwGnEIZybnH3kWbWFXgZOJEQ+AuBL7t7Rbb9lZaWuubq2TXcYdYsuOQSWLsWxo2D\nj3+8eaC5w8UXw+OPw4knwowZ0NKI3DvvwMqVDUMp9c89e8K//gX33x8Cv6wsBOhnPgNnnBHGvpcu\nhYqK8KiqarzdgoJwAKh/vPde2E9NTUOZAQPgyCPh5JND2B90UO5/j7o6eO45eOABePhhePvt1v09\nCwrCNnr2hEsvDY+99mrdNkR2hpm94O6lOZXNFvxmdh/wKaAP8DZwJaE3j7tPMzMDbiVc+VMNTHD3\nsuizpwA3AwXADHe/JpdKJTn4q6vD0MqAAe0/7ltREcJ8zhw4/HC45Rb41Kcyl3eH228PB4kuXeDm\nm+FrX2uo59tvwx/+AL/7Hcyd2ziM0zn6aDj7bBg/Hvbfv/n6urpwMKqoCNv+97+bP4qKYOjQhseh\nh4YhlHyorYW//S0cqJqeE+jZM7QvdTis/nVhIUyaFIatRHaVvAZ/R0hC8G/eDE89FXqrK1eGYYlV\nq2B9NBh2yCEhFL/8ZTjwwOzbq6kJn6+oCD3m+l7zO+/AfvuFx/77N7xeuRJ+9aswdPLjH4eg6prj\nwN8rr8CECfDXv4ax8BNOCN8ann02HBw+8hH4whfCN4cdO5oPkRQUwJgxMEwX94rkjYK/E9u6NQTu\ntdeG3iGEMe2DDgqPIUNCGM+aBc88E9Yfd1w4CJx5ZgjNFSvC4+WXG16vWAHbt4fyZuFgMXx4GKp5\n+2148014663wurY2lJk4EX7yk507mVpXF74hTJkS2nT44WGY6AtfCPvVVSoiu5aCvxOqqYE774Qf\n/QjWrQvjz//zPzBiROYx4Ndeg/vug7vuCr13s9CjrldQEAL+kEPCEMfhh4eToUOHhqGIdOrqwgGn\nri4ccNrqjTdCL769rvYRkdwo+DsRd3jkkRDyK1aEa8Wvuy4Mj7RmG0uWhG8BvXqFoD/44BD6hYXt\nV3cR2X20Jvg7zXX8cVJVFa4br7+G/JVXQi981iwYO7b1wyBm4SqVI49sn/qKSLIo+PNk9Wr4/e/D\n5Y7z5oXx9p49w6WPV10VTtIWFHR0LUVEFPxttnEjXHkl/PrX4aTpYYfB5Mnh+vFPfAK6d+/oGoqI\nNKbg30nbt8Ott8LVV4dfuk6aFObY0DRDItLZKfhbyT38SOl73wvXzY8eDT/7ma5JF5Hdh6aGaoW3\n3oKTToLTTw9X0/z5zzB7tkJfRHYv6vHnaNmy0LuvrAxDPN/4Ru6/dBUR6UwUXTl4+unwq9QePcIV\nO8cc09E1EhHZeQr+LO6+G847L0ylMHs2HHBAR9dIJGZqaprPk51phr8uXRrPlFdUFMZd63/Wvn17\n44mhqqsb/9y9sygqCnOlFBd3yM0YFPwZuId5bH74Q/j0p8Ovb9vj7kwirVYfcPXBlhqY6W4cUF0d\nJlQqLGw+zWhRUfjFYdMpRjduDOGbblpSSF/+3XdbF7L17dixo21/jy5dwnXTW7d2zpBvSZcuYX7x\n+nnQBw4M87S0MwV/Gjt2hDH8mTPhnHPCVMSaGqGducOCBWGu5m7dOro2Ha+yMty04KWXmofspk0h\n5NpDYWHDjRi6dUt/UIHGYTVgQJh0amd6r927N+/B9+yZ+b+B2tpQj6b12ro1jMU23U6PHp3vl5Pu\nDXf/SXfw3AUU/GlccUUI/R/+MEyqppkm29nq1WGq0Llz4ayzwvha3O5FWH9VQElJmK966NDmbayp\nCZeKzZwZbge2Y0cI1r59w/OgQVBaGl4XF6fvjae+Tn3fvXvjbwmpodmzZ0OI77FHy//Bu4dH3P59\nEkbB38Rf/hKuy//mN8NUC9KOamrgf/83/PS5Wzf44hfD19yBA+H663d+u2++GW4W8NnPhp5pR3v3\n3VCXRYsalu29N3zsY+EgcNRRob533RXmzd533/Dz7wkTwhzX+dKjR9tvB2amnlAMKPhTbNgA554b\npl246aaOrk3MlZfDBReEO5KPHQtTp8KHPwwf+hDccEMI/wsvbP12a2rCDy3mzw8Hk89+Ntw4d8yY\njrkHYlVVuHnv0qXh6oCDDoK//z08nnsufK2EcG3wqaeGsD/lFA13SbtS8Efq6uCrXw13rHryyfAN\nWVJUV4dpRl9/PTxeey08r1sX5pieMiW3nuC2bWH87MYbw/DCQw+Fu7fUf/aXvwzbnDw5DIuMGdO6\net54Ywj9664LY6YPPhiGTbp3D4F65plw7LFh2KS9e67btoWD0PPPh5v4jh4dlg8ZEv5jg/Af3KJF\nobehezXKruLune5xzDHH+K7285+HwcupU3f5rne9ujr3TZtyK/vmm+6XXOLes2f96G54dOniXlLi\nfthh4f1ll4XttuT9991POimUP++8zHV4/333//gP96Ii93/8I/d2LVni3q2b+5lnNtSlttb9uefc\nJ09232+/hvrvvbf78ce7X3yx+x13uJeXu2/blvu+stmxw/3008O+Zs7M33ZFMgDKPMeMza1QuJH6\nCmAVcHma9b2BWcASYAEwPGXdxcBSoAL4Ti7729XB/89/hrwYOzZ7dsXCd78b/ulHjnS/6Sb3119v\nXmbdOvdvf9u9R48Q8mef7X7ffe5/+5v7a6+FYHMPf7ALLwzb+/73M+/z3/92//jHw7buuCN7Hd9+\n2/3AA9379HFfuTJ7+W3b3EeMcN93X/fKyvRlamrcFyxwnzbNfdIk92OPDQeX+oNBYaH7UUe5T5jg\nfsst7vPmub/7bvZ9N1Vb637OOWGbt9zS+s+L7IS8Bj9QAKwGDgQKgcXAsCZlbgSujF4fCsyJXg+P\nQr8nYVjpKeCgbPvclcH/3nvuBx/s3r+/+8aNbdjQmjXuy5eH/+k7sxkzwj/7Kae4H310Q+gdd5z7\nL38ZjoIXXhhCsKAghGC24K2tdf/618N2rrqq+foNG0Kgduvm/vDDudf15Zfd99nH/aCDwoGgJT/8\nYdj/rFm5b989HAyWLXO/997wreXkk9379m387Wavvdz79XMfPDh8wyktdf/kJ0NP4aKL3G+4IXz+\n2WfdX3214UD4k5+0ri4ibdCa4M9ljH8ksMrd1wCY2f3AWOCllDLDgOujoaPlZjbIzPoBQ4H57l4d\nffavwDjgpznsd5e4+GJYuRLmzAlXs7XaW2/B978PM2aEmOjVC444IlypMWJEeC4ubhgbT30UFYWr\nWgYMyHu70nruufADhZNOClOMdu0aGv/AA+ExeXIo160bfO1rYdx+8ODs2+3SBaZNC5cf1l+hM2VK\nWLd+PXzmM7B2Lfzxj+Fka66GDAmfOeGE8LecOjWMmTdVVgbXXBN+dHHaablvH8I13oceGh5nnRWW\nuYcrg8rLw2PDhsbXsdc/r14NzzyT/trryy4L1wWLdEJZ77lrZmcAo9z9guj9OcBH3f2ilDLXAkXu\n/l9mNhL4O/BRoBr4A/AxYAswh3BUmpxmPxOBiQADBw48Zu3atXloXsv+OHMjD5z3OKeeVshZ5ze5\n7nnvvcP8DJlOAG7dGkL72mvDSbyLLgp3O68Pi/Jy2Lw5/Wf79Alhv2pVuMTuoYfg+ONbrmxtbbi9\n17ZtDT+w6dMnXAWTy6/L1q4NN/zde+9w8jPdZY4vvRQmIxo9eufmpqitDSct77knnGQdNy6E/saN\n8Kc/wX/+Z+u3CeHKn/PPh8WLw4ngW2+F/fYL67ZuDT/62rwZXnyxYy7ffO+9xgf0Xr1g/Hhd9ii7\nVGvuuZvLUM8ZwO0p788Bbm1SZi9gJlAO3AUsBEZE684HXgDmAbcBN2fb564Y6tnyxr/85a5DG3+l\nb/rYZx/3z3/e/brr3P/6V/eqqjCmff/97gccEMqMHRuGJJqqrXVfvToMbcyc6f7UU6FcdXVDmWXL\n3A85JAyp3Hxz5hMMTz8dxq8z1XPPPUM9lixJ//n33nM/8shwQnPZsjb+5bLYscP9S18K9SouDn/D\nhQvbvt3t292vvda9e/ew3dtvD3+v730v7Ovxx9u+D5HdGHke4/8Y8ETK+ynAlBbKG/AqsFeaddcC\nF2bbZ7sH/5Yt/trgT/pWCn3x1b93f/FF9/nz3Z95xn327BDWt90WxrcPOaQhYLt2dR84MLw+8kj3\nOXPaXpd333U/7bSwza98JRxc6q1c2bBu4ED3e+4JV5/MmeP+wAPuv/qV+9VXu3/zmyHUzcJJxTVr\nGrZRW+s+blw4qbqrwnH79hD+JSXuS5fmd9srVoTxdQgnZ83cJ07M7z5EdkP5Dv6uwBpgMA0ndw9r\nUqYYKIxefx34v5R1+0bPA4HlQHG2fbZr8NfW+taxX3QHv2HEvbl9prLS/Y9/dJ8yxf3UU91/85tw\nUjCPdfIf/ziE2IgR7osWuV96aTgZ2quX+zXXNP6mkM6mTe7//d/hKpxu3cJJx7fecv/BD8I/889/\nnr/65iqff6NUtbXuv/51OOk6eLD75s3tsx+R3Uhegz9sj1OAlwlX9/xPtGwSMMkbvhW8TLjk8xGg\nd8pnnyWcCF4MnJjL/to1+C+91B38e/bTvHdG2+xPfwo9dwgHgfPOc3/jjdZtY9069298Iwwf1V+q\neN558bxOddOmNl6KJRIfrQn+rCd3O0JpaamXlZXlf8O33AIXX8yvunyLRRN+yW9u74Qn31atCvWc\nMCFcEdSW7fzoR+EKlHvvDb9cFZHYas3J3eQE/yOPwBlnsHD/MZzw79/x8uoC9t8/v7sQEekorQn+\nZMyt+ve/w1e+wnuHfZTj37iXSy9T6ItIcsU/+LdsgS9/Ge/fn7N6Psre+/Xku9/t6EqJiHSc+Af/\nTTfB2rX87au386cFfbnqqnCvCRGRpIr3GP/69XDwwdSdPIpDK35H166wZEmYqUBEJE5aM8Yf7wic\nMgVqa7lnxI2s/H2Y9kWhLyJJF9+hnvnzw63sLrmE3z59ICNGhBsciYgkXTyDv64uTLu5334wZQrv\nvw/9+2vOLBERiOtQz733hh7/zJmw555UV4cJN0VEJI49/qoquPxyKC0Nd04HBb+ISIr49fhvuCFc\nzfPAA+EGISj4RURSxavHv3ZtuAHI+PFw3HEfLFbwi4g0iFfwX3ZZOIN7ww0fLHJX8IuIpIpP8L/z\nDjz/fAj/gQM/WLxtWwh/Bb+ISBCfMf7iYli+vNk1m1VV4VnBLyISxCf4IW26V1dnXCUikkjxGerJ\nQMEvItKYgl9EJGESE/y9enVsPUREOoucgt/MRpnZCjNbZWaXp1nf28xmmdkSM1tgZsNT1v2XmVWY\n2VIzu8/MeuSzAdmoxy8i0ljW4DezAmAqMBoYBpxlZsOaFLsCKHf3I4BzgV9En+0PfBsodffhQAEw\nPn/Vz07BLyLSWC49/pHAKndf4+7bgfuBsU3KDAPmArj7cmCQmfWL1nUFisysK9ATeCMvNc+Rgl9E\npLFcgr8/8HrK+3XRslSLgXEAZjYSOAAocff1wM+A14A3gXfd/S9trXRrKPhFRBrL18nd64FiMysH\nJgOLgFoz6034djAY+DDQy8zOTrcBM5toZmVmVlZZWZmnain4RUSayiX41wMDUt6XRMs+4O6b3X2C\nu48gjPH3BdYAnwFecfdKd98BPAJ8PN1O3H26u5e6e2nfvn13oinpKfhFRBrLJfgXAkPMbLCZFRJO\nzj6aWsDMiqN1ABcA89x9M2GI51gz62lmBpwILMtf9bOrD/4eu/RaIhGRzivrlA3uXmNmFwFPEK7K\nmeHuFWY2KVo/DRgK3GlmDlQA50fr5pvZw8A/gRrCEND0dmlJBlVVobev2y6KiAQ5zdXj7rOB2U2W\nTUt5/TxwcIbPXglc2YY6tommZBYRaSwRv9xV8IuINFDwi4gkTCKCX/P0iIg0SETwq8cvItJAwS8i\nkjAKfhGRhFHwi4gkjIJfRCRhFPwiIgkT++Cvn7JBRESCWAf/jh1QU6PgFxFJFevg15TMIiLNKfhF\nRBImEcGvKRtERBokIvjV4xcRaaDgFxFJGAW/iEjCKPhFRBJGwS8ikjA5Bb+ZjTKzFWa2yswuT7O+\nt5nNMrMlZrbAzIZHyw8xs/KUx2Yz+06+G5GJgl9EpLmsN1s3swJgKnASsA5YaGaPuvtLKcWuAMrd\n/XQzOzQqf6K7rwBGpGxnPTArz23ISMEvItJcLj3+kcAqd1/j7tuB+4GxTcoMA+YCuPtyYJCZ9WtS\n5kRgtbuvbWOdc1ZVFZ4V/CIiDXIJ/v7A6ynv10XLUi0GxgGY2UjgAKCkSZnxwH07V82dU9/jLyra\nlXsVEenc8nVy93qg2MzKgcnAIqC2fqWZFQJjgIcybcDMJppZmZmVVVZW5qVS1dVQWAhdsw5oiYgk\nRy6RuB4YkPK+JFr2AXffDEwAMDMDXgHWpBQZDfzT3d/OtBN3nw5MBygtLfVcKp9NdbWmaxARaSqX\nHv9CYIiZDY567uOBR1MLmFlxtA7gAmBedDCodxa7eJgHdBMWEZF0svb43b3GzC4CngAKgBnuXmFm\nk6L104ChwJ1m5kAFcH79582sF+GKoG+0Q/1bpOAXEWkup9Fvd58NzG6ybFrK6+eBgzN8tgrYpw11\n3GkKfhGR5mL/y10Fv4hIYwp+EZGEUfCLiCSMgl9EJGEU/CIiCRPr4K+qUvCLiDQV6+BXj19EpLnY\nBn9dHWzdqikbRESaim3wb9kSntXjFxFpLLbBr5uwiIikp+AXEUkYBb+ISMIo+EVEEkbBLyKSMAp+\nEZGEUfCLiCSMgl9EJGFiG/xVVeFZwS8i0lhsg189fhGR9HIKfjMbZWYrzGyVmV2eZn1vM5tlZkvM\nbIGZDU9ZV2xmD5vZcjNbZmYfy2cDMqkPfs3VIyLSWNbgN7MCYCowGhgGnGVmw5oUuwIod/cjgHOB\nX6Ss+wXwuLsfChwJLMtHxbOproaCAujWbVfsTURk95FLj38ksMrd17j7duB+YGyTMsOAuQDuvhwY\nZGb9zGxv4JPAb6N12939nbzVvgX1UzKb7Yq9iYjsPnIJ/v7A6ynv10XLUi0GxgGY2UjgAKAEGAxU\nAjPNbJGZ3W5mu2TwRXPxi4ikl6+Tu9cDxWZWDkwGFgG1QFfgaOA2dz8KqAKanSMAMLOJZlZmZmWV\nlZVtrpCCX0QkvVyCfz0wIOV9SbTsA+6+2d0nuPsIwhh/X2AN4dvBOnefHxV9mHAgaMbdp7t7qbuX\n9u3bt5XNaE7BLyKSXi7BvxAYYmaDzawQGA88mlogunKnMHp7ATAvOhi8BbxuZodE604EXspT3Vuk\n4BcRSa9rtgLuXmNmFwFPAAXADHevMLNJ0fppwFDgTjNzoAI4P2UTk4F7ogPDGmBCntuQloJfRCS9\nrMEP4O6zgdlNlk1Lef08cHCGz5YDpW2o406proY+fXb1XkVEOr9Y/3JXPX4RkeZiG/xVVQp+EZF0\nYhv81dWarkFEJJ1YB796/CIizcUy+N0V/CIimcQy+Ldvh7o6Bb+ISDqxDH7NxS8ikpmCX0QkYRT8\nIiIJo+AXEUkYBb+ISMIo+EVEEkbBLyKSMLEM/qqq8KwpG0REmotl8KvHLyKSmYJfRCRhFPwiIgkT\n6+Dv0aNj6yEi0hnFNviLiqBLLFsnItI2sYxGTcksIpJZTsFvZqPMbIWZrTKzy9Os721ms8xsiZkt\nMLPhKeteNbMXzazczMryWflMFPwiIpl1zVbAzAqAqcBJwDpgoZk96u4vpRS7Aih399PN7NCo/Ikp\n6z/t7hvzWO8WKfhFRDLLpcc/Eljl7mvcfTtwPzC2SZlhwFwAd18ODDKzfnmtaSso+EVEMssl+PsD\nr6e8XxctS7UYGAdgZiOBA4CSaJ0DT5nZC2Y2MdNOzGyimZWZWVllZWWu9U9LwS8iklm+Tu5eDxSb\nWTkwGVgE1EbrPuHuI4DRwLfM7JPpNuDu09291N1L+/bt26bKVFdrugYRkUyyjvED64EBKe9LomUf\ncPfNwAQAMzPgFWBNtG599LzBzGYRho7mtbnmLaiqgn4dNtAkItK55dLjXwgMMbPBZlYIjAceTS1g\nZsXROoALgHnuvtnMepnZnlGZXsDJwNL8VT89DfWIiGSWtcfv7jVmdhHwBFAAzHD3CjObFK2fBgwF\n7jQzByqA86OP9wNmhS8BdAXudffH89+MxhT8IiKZ5TLUg7vPBmY3WTYt5fXzwMFpPrcGOLKNdWw1\nBb+ISGb65a6ISMLELvhramD7dgW/iEgmsQv+LVvCs4JfRCS92AW/5uIXEWmZgl9EJGEU/CIiCaPg\nFxFJmNgGv+bqERFJL3bBX1UVntXjFxFJL3bBr6EeEZGWKfhFRBJGwS8ikjAKfhGRhIlt8BcVdWw9\nREQ6q1gGf7du4SEiIs3FMvg1zCMikpmCX0QkYRT8IiIJE8vg13QNIiKZ5RT8ZjbKzFaY2SozuzzN\n+t5mNsvMlpjZAjMb3mR9gZktMrPH8lXxTNTjFxFpWdbgN7MCYCowGhgGnGVmw5oUuwIod/cjgHOB\nXzRZfzGwrO3Vza6qSsEvItKSXHr8I4FV7r7G3bcD9wNjm5QZBswFcPflwCAz6wdgZiXAqcDteat1\nC9TjFxFpWS7B3x94PeX9umhZqsXAOAAzGwkcAJRE624GLgPqWtqJmU00szIzK6usrMyhWukp+EVE\nWpavk7vXA8VmVg5MBhYBtWb2OWCDu7+QbQPuPt3dS929tG/fvjtdEQW/iEjLuuZQZj0wIOV9SbTs\nA+6+GZgAYGYGvAKsAb4EjDGzU4AewF5mdre7n52Huqel4BcRaVkuPf6FwBAzG2xmhcB44NHUAmZW\nHK0DuACY5+6b3X2Ku5e4+6Doc3PbM/RBwS8ikk3WHr+715jZRcATQAEww90rzGxStH4aMBS408wc\nqADOb8c6t1BXBb+ISDa5DPXg7rOB2U2WTUt5/TxwcJZtPAM80+oatsLWreFZwS8iklmsfrmrufhF\nRLKLZfBrygYRkcxiGfzq8YuIZKbgFxFJmFgFf1VVeFbwi4hkFqvgV49fRCQ7Bb+ISMIo+EVEEkbB\nLyKSMAp+EZGEUfCLiCRM7ILfDLp37+iaiIh0XrEL/l69QviLiEh6sQt+DfOIiLRMwS8ikjAKfhGR\nhIlV8FdVKfhFRLKJVfCrxy8ikp2CX0QkYXIKfjMbZWYrzGyVmV2eZn1vM5tlZkvMbIGZDY+W94je\nLzazCjO7Kt8NSKXgFxHJLmvwm1kBMBUYDQwDzjKzYU2KXQGUu/sRwLnAL6Ll24AT3P1IYAQwysyO\nzVflm1Lwi4hkl0uPfySwyt3XuPt24H5gbJMyw4C5AO6+HBhkZv08eD8q0y16eH6q3pyCX0Qku1yC\nvz/wesr7ddGyVIuBcQBmNhI4ACiJ3heYWTmwAXjS3ee3tdKZKPhFRLLL18nd64HiKOAnA4uAWgB3\nr3X3EYQDwcj68f+mzGyimZWZWVllZeVOVWLMGDjmmJ36qIhIYnTNocx6YEDK+5Jo2QfcfTMwAcDM\nDHgFWNOkzDtm9jQwCljadCfuPh2YDlBaWrpTw0F33bUznxIRSZZcevwLgSFmNtjMCoHxwKOpBcys\nOFoHcAEwz903m1lfMyuOyhQBJwHL81d9ERFpraw9fnevMbOLgCeAAmCGu1eY2aRo/TRgKHCnmTlQ\nAZwffXz/aHkB4SDzoLs/1g7tEBGRHJl7u11ks9NKS0u9rKyso6shIrLbMLMX3L00l7Kx+uWuiIhk\np+AXEUkYBb+ISMIo+EVEEkbBLyKSMJ3yqh4zqwTW7uTH+wAb81id3YXanSxqd7Lk0u4D3L1vLhvr\nlMHfFmZWluslTXGidieL2p0s+W63hnpERBJGwS8ikjBxDP7pHV2BDqJ2J4vanSx5bXfsxvhFRKRl\ncezxi4hIC2IT/NluCB8nZjbDzDaY2dKUZR8ysyfNbGX03Lsj65hvZjbAzJ42s5fMrMLMLo6Wx73d\nPcxsgZnzzgDAAAACiklEQVQtjtp9VbQ81u2uF93Bb5GZPRa9T0q7XzWzF82s3MzKomV5a3ssgj/H\nG8LHyR2EG9qkuhyY4+5DgDnR+zipAS5192HAscC3on/juLd7G3CCux8JjABGmdmxxL/d9S4GlqW8\nT0q7AT7t7iNSLuPMW9tjEfzkdkP42HD3ecC/miweC9wZvb4TOG2XVqqdufub7v7P6PV7hDDoT/zb\n7e7+fvS2W/RwYt5uADMrAU4Fbk9ZHPt2tyBvbY9L8OdyQ/i46+fub0av3wL6dWRl2pOZDQKOAuaT\ngHZHwx3lwAbgSXdPRLuBm4HLgLqUZUloN4SD+1Nm9oKZTYyW5a3tudxzV3Yz7u7R3dBix8z2AH4H\nfCe6vecH6+LabnevBUZEtzGdZWbDm6yPXbvN7HPABnd/wcw+la5MHNud4hPuvt7M9gWeNLNGt6xt\na9vj0uPPekP4BHjbzPYHiJ43dHB98s7MuhFC/x53fyRaHPt213P3d4CnCed34t7u44AxZvYqYej2\nBDO7m/i3GwB3Xx89bwBmEYaz89b2uAR/1hvCJ8CjwFej118F/tCBdck7C1373wLL3P3nKavi3u6+\nUU8fMysCTgKWE/N2u/sUdy9x90GE/5/nuvvZxLzdAGbWy8z2rH8NnAwsJY9tj80PuMzsFMKYYP0N\n4a/p4Cq1GzO7D/gUYca+t4Ergd8DDwIDCTObftHdm54A3m2Z2SeAZ4EXaRjzvYIwzh/ndh9BOJFX\nQOioPejuV5vZPsS43amioZ7vuvvnktBuMzuQ0MuHMBx/r7tfk8+2xyb4RUQkN3EZ6hERkRwp+EVE\nEkbBLyKSMAp+EZGEUfCLiCSMgl9EJGEU/CIiCaPgFxFJmP8HGiTD9wBZHY0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb55c119be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "model2.compile(loss= 'categorical_crossentropy' , optimizer= adam , metrics=[ 'accuracy' ])\n",
    "\n",
    "# Fit the model\n",
    "t0=time.time()\n",
    "log2 = model2.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=200, verbose=2)\n",
    "t1=time.time()\n",
    "print(t1-t0,\" seconds\")\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores2 = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores2[1]*100))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(log2.history['acc'],'b') \n",
    "plt.plot(log2.history['val_acc'],'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with 1x1 conv takes longer. The performances fluctuate, so it's hard to tell which is better.\n",
    "Seems the parallel paths (towers) helps when compared to two-layer-deep models we used previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. \n",
    "Apply BatchNorm after every conv or dense layers for the inception module 2. \n",
    "Compare the performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception2BN(x, n = 32):\n",
    "    p1 = Conv2D(n, 1, padding='same')(x)\n",
    "    p1 = BatchNormalization()(p1)\n",
    "    p1 = Activation('relu')(p1)\n",
    "    p2 = Conv2D(n, 1, padding='same')(x)\n",
    "    p2 = BatchNormalization()(p2)\n",
    "    p2 = Activation('relu')(p2)\n",
    "    p2 = Conv2D(n, 3, padding='same')(p2)\n",
    "    p2 = BatchNormalization()(p2)\n",
    "    p2 = Activation('relu')(p2)    \n",
    "    p3 = Conv2D(n, 1, padding='same')(x)\n",
    "    p3 = BatchNormalization()(p3)\n",
    "    p3 = Activation('relu')(p3)    \n",
    "    p3 = Conv2D(n, 5, padding='same')(p3)\n",
    "    p3 = BatchNormalization()(p3)\n",
    "    p3 = Activation('relu')(p3)  \n",
    "    p4 = MaxPooling2D((3,3), strides=(1, 1), padding='same')(x)    \n",
    "    p4 = Conv2D(n, 1, padding='same')(p4)\n",
    "    p4 = BatchNormalization()(p4)\n",
    "    p4 = Activation('relu')(p4)     \n",
    "\n",
    "    c =  Concatenate(axis=-1)([p1,p2,p3,p4])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model3():\n",
    "    inputs = Input(X_train.shape[1:])\n",
    "    i1 = inception2BN(inputs)\n",
    "    mp1 = MaxPooling2D((2,2))(i1)\n",
    "    i2 = inception2BN(mp1)\n",
    "    mp2 = MaxPooling2D((2,2))(i2) \n",
    "    f = Flatten()(mp2)\n",
    "    d = Dense(128)(f)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Activation('relu')(d)\n",
    "    out = Dense(10, activation='softmax')(d)\n",
    "    model = Model(inputs, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      " - 19s - loss: 0.1169 - acc: 0.9684 - val_loss: 1.5253 - val_acc: 0.2990\n",
      "Epoch 2/50\n",
      " - 17s - loss: 0.0327 - acc: 0.9914 - val_loss: 0.0736 - val_acc: 0.9794\n",
      "Epoch 3/50\n",
      " - 18s - loss: 0.0176 - acc: 0.9956 - val_loss: 0.0816 - val_acc: 0.9759\n",
      "Epoch 4/50\n",
      " - 18s - loss: 0.0115 - acc: 0.9973 - val_loss: 0.0419 - val_acc: 0.9871\n",
      "Epoch 5/50\n",
      " - 19s - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0453 - val_acc: 0.9864\n",
      "Epoch 6/50\n",
      " - 18s - loss: 0.0068 - acc: 0.9983 - val_loss: 0.0761 - val_acc: 0.9781\n",
      "Epoch 7/50\n",
      " - 18s - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0419 - val_acc: 0.9885\n",
      "Epoch 8/50\n",
      " - 18s - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0403 - val_acc: 0.9878\n",
      "Epoch 9/50\n",
      " - 18s - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0389 - val_acc: 0.9888\n",
      "Epoch 10/50\n",
      " - 18s - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0416 - val_acc: 0.9887\n",
      "Epoch 11/50\n",
      " - 18s - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0645 - val_acc: 0.9811\n",
      "Epoch 12/50\n",
      " - 18s - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0315 - val_acc: 0.9908\n",
      "Epoch 13/50\n",
      " - 19s - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0351 - val_acc: 0.9901\n",
      "Epoch 14/50\n",
      " - 18s - loss: 7.9477e-04 - acc: 0.9999 - val_loss: 0.0257 - val_acc: 0.9924\n",
      "Epoch 15/50\n",
      " - 18s - loss: 2.9686e-04 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9923\n",
      "Epoch 16/50\n",
      " - 18s - loss: 1.6282e-04 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 0.9933\n",
      "Epoch 17/50\n",
      " - 18s - loss: 1.1874e-04 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 0.9931\n",
      "Epoch 18/50\n",
      " - 18s - loss: 8.8741e-05 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9932\n",
      "Epoch 19/50\n",
      " - 17s - loss: 7.5202e-05 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 0.9933\n",
      "Epoch 20/50\n",
      " - 18s - loss: 6.5003e-05 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 0.9935\n",
      "Epoch 21/50\n",
      " - 18s - loss: 5.7442e-05 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9933\n",
      "Epoch 22/50\n",
      " - 19s - loss: 4.8658e-05 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9933\n",
      "Epoch 23/50\n",
      " - 18s - loss: 4.4448e-05 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9932\n",
      "Epoch 24/50\n",
      " - 19s - loss: 3.4888e-05 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9931\n",
      "Epoch 25/50\n",
      " - 18s - loss: 2.9366e-05 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 0.9933\n",
      "Epoch 26/50\n",
      " - 17s - loss: 2.7099e-05 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9931\n",
      "Epoch 27/50\n",
      " - 19s - loss: 2.3562e-05 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 0.9932\n",
      "Epoch 28/50\n",
      " - 18s - loss: 2.0256e-05 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9929\n",
      "Epoch 29/50\n",
      " - 19s - loss: 1.7894e-05 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 0.9931\n",
      "Epoch 30/50\n",
      " - 19s - loss: 1.6033e-05 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 0.9934\n",
      "Epoch 31/50\n",
      " - 18s - loss: 1.5655e-05 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 0.9929\n",
      "Epoch 32/50\n",
      " - 18s - loss: 1.2764e-05 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9931\n",
      "Epoch 33/50\n",
      " - 18s - loss: 1.1468e-05 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 0.9935\n",
      "Epoch 34/50\n",
      " - 18s - loss: 9.4774e-06 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9933\n",
      "Epoch 35/50\n",
      " - 18s - loss: 8.0763e-06 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9931\n",
      "Epoch 36/50\n",
      " - 18s - loss: 7.0612e-06 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9930\n",
      "Epoch 37/50\n",
      " - 18s - loss: 6.4852e-06 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9933\n",
      "Epoch 38/50\n",
      " - 17s - loss: 5.9561e-06 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 39/50\n",
      " - 18s - loss: 5.8249e-06 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9933\n",
      "Epoch 40/50\n",
      " - 18s - loss: 4.9662e-06 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9929\n",
      "Epoch 41/50\n",
      " - 18s - loss: 4.2063e-06 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9932\n",
      "Epoch 42/50\n",
      " - 18s - loss: 3.5779e-06 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 43/50\n",
      " - 18s - loss: 3.1330e-06 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9937\n",
      "Epoch 44/50\n",
      " - 18s - loss: 4.2072e-06 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9931\n",
      "Epoch 45/50\n",
      " - 18s - loss: 2.7500e-06 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 0.9930\n",
      "Epoch 46/50\n",
      " - 18s - loss: 2.1281e-06 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9932\n",
      "Epoch 47/50\n",
      " - 18s - loss: 1.9759e-06 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9931\n",
      "Epoch 48/50\n",
      " - 17s - loss: 1.6113e-06 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9928\n",
      "Epoch 49/50\n",
      " - 18s - loss: 1.4232e-06 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9928\n",
      "Epoch 50/50\n",
      " - 18s - loss: 1.3067e-06 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9933\n",
      "902.8872182369232  seconds\n",
      "CNN Error: 0.65%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb49fb10ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = model3()\n",
    "adam = Adam(lr=0.001)\n",
    "model3.compile(loss= 'categorical_crossentropy' , optimizer= adam , metrics=[ 'accuracy' ])\n",
    "\n",
    "# Fit the model\n",
    "t0=time.time()\n",
    "log3 = model3.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=200, verbose=2)\n",
    "t1=time.time()\n",
    "print(t1-t0,\" seconds\")\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores3 = model3.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores3[1]*100))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(log3.history['acc'],'b') \n",
    "plt.plot(log3.history['val_acc'],'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "BatchNorm makes it converge faster, and improved the result somewhat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
