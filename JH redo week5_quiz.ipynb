{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>cigs</th>\n",
       "      <th>years</th>\n",
       "      <th>fbs</th>\n",
       "      <th>famhist</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  cigs  years  fbs  famhist  restecg  thalach  \\\n",
       "0   63    1   1       145   233  50.0   20.0    1        1        2      150   \n",
       "1   67    1   4       160   286  40.0   40.0    0        1        2      108   \n",
       "2   67    1   4       120   229  20.0   35.0    0        1        2      129   \n",
       "3   37    1   3       130   250   0.0    0.0    0        1        0      187   \n",
       "4   41    0   2       130   204   0.0    0.0    0        1        2      172   \n",
       "\n",
       "   exang  thal  num  \n",
       "0      0     6    0  \n",
       "1      1     3    2  \n",
       "2      1     7    1  \n",
       "3      0     3    0  \n",
       "4      0     3    0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the csv file is under the week 2 content\n",
    "filename = 'C:/MSDS/MachL/Wk6/heart.disease.data.clean.csv'\n",
    "heart_df = pd.read_csv(filename)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set values of target column to 0 (no heart disease) and 1 (heart disease)\n",
    "heart_df.loc[heart_df['num'] > 0, 'num'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    157\n",
       "1    125\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df['num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [c for c in heart_df.columns if c != 'num']\n",
    "# select features and columns from the dataframe as we did in the neural net exercise\n",
    "features = heart_df[feat_cols].values\n",
    "targets = heart_df['num'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    targets,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=223,\n",
    "                                                    stratify=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "inputs = Input(shape=(features.shape[1], ))\n",
    "# complete the neural net design\n",
    "x1 = Dense(200, activation='elu')(inputs)\n",
    "x2 = Dense(50, activation='tanh')(x1)\n",
    "predictions = Dense(1, activation='sigmoid')(x2)\n",
    "\n",
    "model = Model(inputs, predictions)\n",
    "# choose an optimizer and use the correct loss for binary classification\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191 samples, validate on 34 samples\n",
      "Epoch 1/500\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.3087 - acc: 0.5026 - val_loss: 0.2762 - val_acc: 0.5588\n",
      "Epoch 2/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.2369 - acc: 0.5812 - val_loss: 0.2425 - val_acc: 0.6471\n",
      "Epoch 3/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2415 - acc: 0.6073 - val_loss: 0.2310 - val_acc: 0.6176\n",
      "Epoch 4/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2264 - acc: 0.6335 - val_loss: 0.2226 - val_acc: 0.6765\n",
      "Epoch 5/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2251 - acc: 0.6545 - val_loss: 0.2185 - val_acc: 0.7353\n",
      "Epoch 6/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2255 - acc: 0.6649 - val_loss: 0.2234 - val_acc: 0.7059\n",
      "Epoch 7/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2274 - acc: 0.6806 - val_loss: 0.2212 - val_acc: 0.7059\n",
      "Epoch 8/500\n",
      "191/191 [==============================] - 0s 16us/step - loss: 0.2227 - acc: 0.6963 - val_loss: 0.2209 - val_acc: 0.6765\n",
      "Epoch 9/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2216 - acc: 0.6806 - val_loss: 0.2176 - val_acc: 0.6765\n",
      "Epoch 10/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2206 - acc: 0.6649 - val_loss: 0.2138 - val_acc: 0.6765\n",
      "Epoch 11/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2201 - acc: 0.6754 - val_loss: 0.2139 - val_acc: 0.7059\n",
      "Epoch 12/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2194 - acc: 0.6806 - val_loss: 0.2132 - val_acc: 0.7059\n",
      "Epoch 13/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2179 - acc: 0.6859 - val_loss: 0.2134 - val_acc: 0.7353\n",
      "Epoch 14/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2169 - acc: 0.6702 - val_loss: 0.2151 - val_acc: 0.6765\n",
      "Epoch 15/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2160 - acc: 0.6649 - val_loss: 0.2107 - val_acc: 0.7059\n",
      "Epoch 16/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2148 - acc: 0.6649 - val_loss: 0.2033 - val_acc: 0.7059\n",
      "Epoch 17/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2144 - acc: 0.6859 - val_loss: 0.2006 - val_acc: 0.7059\n",
      "Epoch 18/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2141 - acc: 0.7016 - val_loss: 0.1987 - val_acc: 0.7059\n",
      "Epoch 19/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.2139 - acc: 0.6806 - val_loss: 0.1975 - val_acc: 0.7059\n",
      "Epoch 20/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2114 - acc: 0.7016 - val_loss: 0.1977 - val_acc: 0.7353\n",
      "Epoch 21/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.2107 - acc: 0.6806 - val_loss: 0.2048 - val_acc: 0.7059\n",
      "Epoch 22/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.2092 - acc: 0.6963 - val_loss: 0.2073 - val_acc: 0.7059\n",
      "Epoch 23/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2077 - acc: 0.7173 - val_loss: 0.2084 - val_acc: 0.7353\n",
      "Epoch 24/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2082 - acc: 0.7120 - val_loss: 0.2065 - val_acc: 0.7059\n",
      "Epoch 25/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2071 - acc: 0.7277 - val_loss: 0.2045 - val_acc: 0.7059\n",
      "Epoch 26/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.2064 - acc: 0.7173 - val_loss: 0.2037 - val_acc: 0.7059\n",
      "Epoch 27/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2049 - acc: 0.7173 - val_loss: 0.1989 - val_acc: 0.7059\n",
      "Epoch 28/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2037 - acc: 0.7277 - val_loss: 0.1968 - val_acc: 0.7059\n",
      "Epoch 29/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.2024 - acc: 0.7277 - val_loss: 0.1984 - val_acc: 0.7059\n",
      "Epoch 30/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2011 - acc: 0.7225 - val_loss: 0.1975 - val_acc: 0.7353\n",
      "Epoch 31/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.2014 - acc: 0.7173 - val_loss: 0.1964 - val_acc: 0.7647\n",
      "Epoch 32/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.2002 - acc: 0.7225 - val_loss: 0.1936 - val_acc: 0.7353\n",
      "Epoch 33/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1993 - acc: 0.7382 - val_loss: 0.1888 - val_acc: 0.7059\n",
      "Epoch 34/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1984 - acc: 0.7330 - val_loss: 0.1888 - val_acc: 0.7353\n",
      "Epoch 35/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1974 - acc: 0.7173 - val_loss: 0.1915 - val_acc: 0.7353\n",
      "Epoch 36/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1963 - acc: 0.7225 - val_loss: 0.1933 - val_acc: 0.7353\n",
      "Epoch 37/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1952 - acc: 0.7382 - val_loss: 0.1921 - val_acc: 0.7647\n",
      "Epoch 38/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1942 - acc: 0.7277 - val_loss: 0.1896 - val_acc: 0.7647\n",
      "Epoch 39/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.1929 - acc: 0.7330 - val_loss: 0.1879 - val_acc: 0.7647\n",
      "Epoch 40/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1918 - acc: 0.7330 - val_loss: 0.1907 - val_acc: 0.7647\n",
      "Epoch 41/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1899 - acc: 0.7330 - val_loss: 0.1929 - val_acc: 0.7647\n",
      "Epoch 42/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1880 - acc: 0.7382 - val_loss: 0.1914 - val_acc: 0.7647\n",
      "Epoch 43/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1865 - acc: 0.7382 - val_loss: 0.1887 - val_acc: 0.7647\n",
      "Epoch 44/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1859 - acc: 0.7382 - val_loss: 0.1844 - val_acc: 0.7941\n",
      "Epoch 45/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1854 - acc: 0.7277 - val_loss: 0.1841 - val_acc: 0.7647\n",
      "Epoch 46/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1833 - acc: 0.7539 - val_loss: 0.1852 - val_acc: 0.7647\n",
      "Epoch 47/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1822 - acc: 0.7382 - val_loss: 0.1850 - val_acc: 0.7941\n",
      "Epoch 48/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1820 - acc: 0.7592 - val_loss: 0.1846 - val_acc: 0.8235\n",
      "Epoch 49/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1806 - acc: 0.7539 - val_loss: 0.1828 - val_acc: 0.7941\n",
      "Epoch 50/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1792 - acc: 0.7644 - val_loss: 0.1804 - val_acc: 0.7941\n",
      "Epoch 51/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1788 - acc: 0.7539 - val_loss: 0.1788 - val_acc: 0.7941\n",
      "Epoch 52/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1775 - acc: 0.7696 - val_loss: 0.1783 - val_acc: 0.8235\n",
      "Epoch 53/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1765 - acc: 0.7644 - val_loss: 0.1766 - val_acc: 0.7941\n",
      "Epoch 54/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1761 - acc: 0.7696 - val_loss: 0.1759 - val_acc: 0.8529\n",
      "Epoch 55/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1756 - acc: 0.7749 - val_loss: 0.1750 - val_acc: 0.7941\n",
      "Epoch 56/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1751 - acc: 0.7749 - val_loss: 0.1774 - val_acc: 0.8235\n",
      "Epoch 57/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1751 - acc: 0.7749 - val_loss: 0.1766 - val_acc: 0.7941\n",
      "Epoch 58/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1741 - acc: 0.7644 - val_loss: 0.1750 - val_acc: 0.8235\n",
      "Epoch 59/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1724 - acc: 0.7644 - val_loss: 0.1726 - val_acc: 0.8235\n",
      "Epoch 60/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1720 - acc: 0.7749 - val_loss: 0.1714 - val_acc: 0.8529\n",
      "Epoch 61/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1715 - acc: 0.7801 - val_loss: 0.1725 - val_acc: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1708 - acc: 0.7853 - val_loss: 0.1702 - val_acc: 0.8235\n",
      "Epoch 63/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1708 - acc: 0.7696 - val_loss: 0.1712 - val_acc: 0.8235\n",
      "Epoch 64/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1697 - acc: 0.7906 - val_loss: 0.1701 - val_acc: 0.8529\n",
      "Epoch 65/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1689 - acc: 0.7853 - val_loss: 0.1710 - val_acc: 0.8529\n",
      "Epoch 66/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1680 - acc: 0.7853 - val_loss: 0.1701 - val_acc: 0.8235\n",
      "Epoch 67/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1676 - acc: 0.7853 - val_loss: 0.1687 - val_acc: 0.8529\n",
      "Epoch 68/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1665 - acc: 0.7801 - val_loss: 0.1703 - val_acc: 0.8235\n",
      "Epoch 69/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1671 - acc: 0.7906 - val_loss: 0.1679 - val_acc: 0.8529\n",
      "Epoch 70/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1658 - acc: 0.7853 - val_loss: 0.1681 - val_acc: 0.8824\n",
      "Epoch 71/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1655 - acc: 0.7801 - val_loss: 0.1667 - val_acc: 0.8824\n",
      "Epoch 72/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1649 - acc: 0.7958 - val_loss: 0.1668 - val_acc: 0.8824\n",
      "Epoch 73/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1642 - acc: 0.7906 - val_loss: 0.1671 - val_acc: 0.8529\n",
      "Epoch 74/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1634 - acc: 0.7958 - val_loss: 0.1673 - val_acc: 0.8529\n",
      "Epoch 75/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.1628 - acc: 0.7958 - val_loss: 0.1679 - val_acc: 0.8824\n",
      "Epoch 76/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1622 - acc: 0.7958 - val_loss: 0.1662 - val_acc: 0.8529\n",
      "Epoch 77/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1618 - acc: 0.7906 - val_loss: 0.1665 - val_acc: 0.8824\n",
      "Epoch 78/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1611 - acc: 0.8010 - val_loss: 0.1659 - val_acc: 0.8529\n",
      "Epoch 79/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1605 - acc: 0.7906 - val_loss: 0.1656 - val_acc: 0.8824\n",
      "Epoch 80/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1595 - acc: 0.7958 - val_loss: 0.1652 - val_acc: 0.8824\n",
      "Epoch 81/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1591 - acc: 0.8010 - val_loss: 0.1646 - val_acc: 0.8824\n",
      "Epoch 82/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1585 - acc: 0.8010 - val_loss: 0.1649 - val_acc: 0.8824\n",
      "Epoch 83/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1583 - acc: 0.7906 - val_loss: 0.1645 - val_acc: 0.8235\n",
      "Epoch 84/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1577 - acc: 0.7906 - val_loss: 0.1643 - val_acc: 0.8824\n",
      "Epoch 85/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1574 - acc: 0.8010 - val_loss: 0.1639 - val_acc: 0.8529\n",
      "Epoch 86/500\n",
      "191/191 [==============================] - 0s 16us/step - loss: 0.1566 - acc: 0.8010 - val_loss: 0.1637 - val_acc: 0.8529\n",
      "Epoch 87/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1563 - acc: 0.8010 - val_loss: 0.1648 - val_acc: 0.8235\n",
      "Epoch 88/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1556 - acc: 0.8115 - val_loss: 0.1649 - val_acc: 0.8529\n",
      "Epoch 89/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1552 - acc: 0.8063 - val_loss: 0.1650 - val_acc: 0.8235\n",
      "Epoch 90/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1545 - acc: 0.8063 - val_loss: 0.1646 - val_acc: 0.8529\n",
      "Epoch 91/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1541 - acc: 0.8010 - val_loss: 0.1645 - val_acc: 0.8235\n",
      "Epoch 92/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1535 - acc: 0.8115 - val_loss: 0.1643 - val_acc: 0.8529\n",
      "Epoch 93/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1530 - acc: 0.8115 - val_loss: 0.1650 - val_acc: 0.8529\n",
      "Epoch 94/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1526 - acc: 0.8115 - val_loss: 0.1643 - val_acc: 0.8529\n",
      "Epoch 95/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1521 - acc: 0.8115 - val_loss: 0.1640 - val_acc: 0.8529\n",
      "Epoch 96/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1517 - acc: 0.8168 - val_loss: 0.1636 - val_acc: 0.8529\n",
      "Epoch 97/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1513 - acc: 0.8168 - val_loss: 0.1639 - val_acc: 0.8235\n",
      "Epoch 98/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1509 - acc: 0.8115 - val_loss: 0.1634 - val_acc: 0.8529\n",
      "Epoch 99/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1507 - acc: 0.8063 - val_loss: 0.1635 - val_acc: 0.7941\n",
      "Epoch 100/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1505 - acc: 0.8063 - val_loss: 0.1620 - val_acc: 0.8529\n",
      "Epoch 101/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.1506 - acc: 0.8063 - val_loss: 0.1630 - val_acc: 0.7941\n",
      "Epoch 102/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1510 - acc: 0.8010 - val_loss: 0.1604 - val_acc: 0.8529\n",
      "Epoch 103/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1510 - acc: 0.8063 - val_loss: 0.1627 - val_acc: 0.7941\n",
      "Epoch 104/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1495 - acc: 0.8010 - val_loss: 0.1609 - val_acc: 0.8529\n",
      "Epoch 105/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1485 - acc: 0.8115 - val_loss: 0.1601 - val_acc: 0.8529\n",
      "Epoch 106/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1479 - acc: 0.8168 - val_loss: 0.1618 - val_acc: 0.7941\n",
      "Epoch 107/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1483 - acc: 0.8063 - val_loss: 0.1605 - val_acc: 0.8235\n",
      "Epoch 108/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1477 - acc: 0.8168 - val_loss: 0.1609 - val_acc: 0.8529\n",
      "Epoch 109/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1465 - acc: 0.8115 - val_loss: 0.1604 - val_acc: 0.8529\n",
      "Epoch 110/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1461 - acc: 0.8063 - val_loss: 0.1593 - val_acc: 0.8235\n",
      "Epoch 111/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1464 - acc: 0.8168 - val_loss: 0.1603 - val_acc: 0.8235\n",
      "Epoch 112/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1460 - acc: 0.8063 - val_loss: 0.1588 - val_acc: 0.8529\n",
      "Epoch 113/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1450 - acc: 0.8220 - val_loss: 0.1584 - val_acc: 0.8529\n",
      "Epoch 114/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1447 - acc: 0.8168 - val_loss: 0.1592 - val_acc: 0.8529\n",
      "Epoch 115/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1447 - acc: 0.8063 - val_loss: 0.1572 - val_acc: 0.8529\n",
      "Epoch 116/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1444 - acc: 0.8220 - val_loss: 0.1576 - val_acc: 0.8529\n",
      "Epoch 117/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1436 - acc: 0.8115 - val_loss: 0.1577 - val_acc: 0.8529\n",
      "Epoch 118/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1429 - acc: 0.8168 - val_loss: 0.1570 - val_acc: 0.8529\n",
      "Epoch 119/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1428 - acc: 0.8220 - val_loss: 0.1573 - val_acc: 0.8529\n",
      "Epoch 120/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1425 - acc: 0.8063 - val_loss: 0.1565 - val_acc: 0.8529\n",
      "Epoch 121/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1420 - acc: 0.8272 - val_loss: 0.1573 - val_acc: 0.8529\n",
      "Epoch 122/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1413 - acc: 0.8115 - val_loss: 0.1565 - val_acc: 0.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1409 - acc: 0.8115 - val_loss: 0.1560 - val_acc: 0.8529\n",
      "Epoch 124/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1406 - acc: 0.8272 - val_loss: 0.1572 - val_acc: 0.8529\n",
      "Epoch 125/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1403 - acc: 0.8115 - val_loss: 0.1559 - val_acc: 0.8529\n",
      "Epoch 126/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1399 - acc: 0.8272 - val_loss: 0.1559 - val_acc: 0.8529\n",
      "Epoch 127/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1393 - acc: 0.8115 - val_loss: 0.1555 - val_acc: 0.8529\n",
      "Epoch 128/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1387 - acc: 0.8272 - val_loss: 0.1557 - val_acc: 0.8529\n",
      "Epoch 129/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1381 - acc: 0.8168 - val_loss: 0.1547 - val_acc: 0.8529\n",
      "Epoch 130/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1376 - acc: 0.8272 - val_loss: 0.1543 - val_acc: 0.8529\n",
      "Epoch 131/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1371 - acc: 0.8272 - val_loss: 0.1547 - val_acc: 0.8529\n",
      "Epoch 132/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1367 - acc: 0.8220 - val_loss: 0.1532 - val_acc: 0.8529\n",
      "Epoch 133/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.1364 - acc: 0.8325 - val_loss: 0.1536 - val_acc: 0.8529\n",
      "Epoch 134/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1362 - acc: 0.8168 - val_loss: 0.1518 - val_acc: 0.8529\n",
      "Epoch 135/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1364 - acc: 0.8325 - val_loss: 0.1533 - val_acc: 0.8235\n",
      "Epoch 136/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1368 - acc: 0.8115 - val_loss: 0.1503 - val_acc: 0.8529\n",
      "Epoch 137/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1373 - acc: 0.8220 - val_loss: 0.1546 - val_acc: 0.7941\n",
      "Epoch 138/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1377 - acc: 0.8168 - val_loss: 0.1503 - val_acc: 0.8824\n",
      "Epoch 139/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1345 - acc: 0.8325 - val_loss: 0.1501 - val_acc: 0.8529\n",
      "Epoch 140/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1326 - acc: 0.8377 - val_loss: 0.1521 - val_acc: 0.8235\n",
      "Epoch 141/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1327 - acc: 0.8220 - val_loss: 0.1504 - val_acc: 0.8824\n",
      "Epoch 142/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.1338 - acc: 0.8325 - val_loss: 0.1510 - val_acc: 0.8235\n",
      "Epoch 143/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.1349 - acc: 0.8168 - val_loss: 0.1483 - val_acc: 0.8529\n",
      "Epoch 144/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1325 - acc: 0.8482 - val_loss: 0.1500 - val_acc: 0.8529\n",
      "Epoch 145/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1306 - acc: 0.8325 - val_loss: 0.1477 - val_acc: 0.8235\n",
      "Epoch 146/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1320 - acc: 0.8272 - val_loss: 0.1487 - val_acc: 0.8529\n",
      "Epoch 147/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1308 - acc: 0.8482 - val_loss: 0.1512 - val_acc: 0.8235\n",
      "Epoch 148/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1328 - acc: 0.8325 - val_loss: 0.1491 - val_acc: 0.8529\n",
      "Epoch 149/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.1292 - acc: 0.8482 - val_loss: 0.1483 - val_acc: 0.8529\n",
      "Epoch 150/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1299 - acc: 0.8377 - val_loss: 0.1520 - val_acc: 0.8235\n",
      "Epoch 151/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1338 - acc: 0.8272 - val_loss: 0.1518 - val_acc: 0.8529\n",
      "Epoch 152/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1280 - acc: 0.8534 - val_loss: 0.1456 - val_acc: 0.8529\n",
      "Epoch 153/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1285 - acc: 0.8377 - val_loss: 0.1487 - val_acc: 0.8235\n",
      "Epoch 154/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.1296 - acc: 0.8377 - val_loss: 0.1489 - val_acc: 0.8529\n",
      "Epoch 155/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1267 - acc: 0.8586 - val_loss: 0.1489 - val_acc: 0.8235\n",
      "Epoch 156/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1253 - acc: 0.8534 - val_loss: 0.1449 - val_acc: 0.8235\n",
      "Epoch 157/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1274 - acc: 0.8377 - val_loss: 0.1455 - val_acc: 0.8235\n",
      "Epoch 158/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1261 - acc: 0.8586 - val_loss: 0.1491 - val_acc: 0.8235\n",
      "Epoch 159/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1238 - acc: 0.8586 - val_loss: 0.1453 - val_acc: 0.8235\n",
      "Epoch 160/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1247 - acc: 0.8534 - val_loss: 0.1449 - val_acc: 0.8235\n",
      "Epoch 161/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1244 - acc: 0.8482 - val_loss: 0.1478 - val_acc: 0.8529\n",
      "Epoch 162/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1246 - acc: 0.8534 - val_loss: 0.1474 - val_acc: 0.8529\n",
      "Epoch 163/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1221 - acc: 0.8639 - val_loss: 0.1443 - val_acc: 0.8529\n",
      "Epoch 164/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.1232 - acc: 0.8482 - val_loss: 0.1464 - val_acc: 0.8235\n",
      "Epoch 165/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1227 - acc: 0.8534 - val_loss: 0.1500 - val_acc: 0.8235\n",
      "Epoch 166/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1221 - acc: 0.8586 - val_loss: 0.1432 - val_acc: 0.8529\n",
      "Epoch 167/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1207 - acc: 0.8534 - val_loss: 0.1444 - val_acc: 0.8235\n",
      "Epoch 168/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1207 - acc: 0.8639 - val_loss: 0.1506 - val_acc: 0.8235\n",
      "Epoch 169/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.1211 - acc: 0.8639 - val_loss: 0.1450 - val_acc: 0.8529\n",
      "Epoch 170/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1189 - acc: 0.8639 - val_loss: 0.1428 - val_acc: 0.8529\n",
      "Epoch 171/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1192 - acc: 0.8586 - val_loss: 0.1469 - val_acc: 0.8235\n",
      "Epoch 172/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1184 - acc: 0.8639 - val_loss: 0.1460 - val_acc: 0.8529\n",
      "Epoch 173/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1183 - acc: 0.8639 - val_loss: 0.1434 - val_acc: 0.8235\n",
      "Epoch 174/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1179 - acc: 0.8743 - val_loss: 0.1447 - val_acc: 0.8529\n",
      "Epoch 175/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.1169 - acc: 0.8639 - val_loss: 0.1456 - val_acc: 0.8529\n",
      "Epoch 176/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1168 - acc: 0.8639 - val_loss: 0.1424 - val_acc: 0.8235\n",
      "Epoch 177/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1165 - acc: 0.8691 - val_loss: 0.1435 - val_acc: 0.8529\n",
      "Epoch 178/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1159 - acc: 0.8639 - val_loss: 0.1461 - val_acc: 0.8235\n",
      "Epoch 179/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1158 - acc: 0.8691 - val_loss: 0.1416 - val_acc: 0.8529\n",
      "Epoch 180/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.1155 - acc: 0.8639 - val_loss: 0.1428 - val_acc: 0.8235\n",
      "Epoch 181/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1146 - acc: 0.8743 - val_loss: 0.1439 - val_acc: 0.8235\n",
      "Epoch 182/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1144 - acc: 0.8639 - val_loss: 0.1417 - val_acc: 0.8235\n",
      "Epoch 183/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1139 - acc: 0.8691 - val_loss: 0.1424 - val_acc: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1133 - acc: 0.8743 - val_loss: 0.1426 - val_acc: 0.8529\n",
      "Epoch 185/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1134 - acc: 0.8586 - val_loss: 0.1419 - val_acc: 0.8235\n",
      "Epoch 186/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1132 - acc: 0.8796 - val_loss: 0.1414 - val_acc: 0.8529\n",
      "Epoch 187/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1131 - acc: 0.8639 - val_loss: 0.1459 - val_acc: 0.8235\n",
      "Epoch 188/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1133 - acc: 0.8743 - val_loss: 0.1402 - val_acc: 0.8529\n",
      "Epoch 189/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1141 - acc: 0.8639 - val_loss: 0.1441 - val_acc: 0.8235\n",
      "Epoch 190/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1129 - acc: 0.8848 - val_loss: 0.1425 - val_acc: 0.8529\n",
      "Epoch 191/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1127 - acc: 0.8639 - val_loss: 0.1436 - val_acc: 0.8235\n",
      "Epoch 192/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1110 - acc: 0.8796 - val_loss: 0.1405 - val_acc: 0.8235\n",
      "Epoch 193/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1103 - acc: 0.8691 - val_loss: 0.1449 - val_acc: 0.8235\n",
      "Epoch 194/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1098 - acc: 0.8691 - val_loss: 0.1422 - val_acc: 0.8235\n",
      "Epoch 195/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1093 - acc: 0.8691 - val_loss: 0.1398 - val_acc: 0.8235\n",
      "Epoch 196/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1097 - acc: 0.8691 - val_loss: 0.1470 - val_acc: 0.8235\n",
      "Epoch 197/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1104 - acc: 0.8796 - val_loss: 0.1401 - val_acc: 0.8529\n",
      "Epoch 198/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1105 - acc: 0.8691 - val_loss: 0.1409 - val_acc: 0.8235\n",
      "Epoch 199/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1103 - acc: 0.8901 - val_loss: 0.1424 - val_acc: 0.8529\n",
      "Epoch 200/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1104 - acc: 0.8639 - val_loss: 0.1410 - val_acc: 0.8235\n",
      "Epoch 201/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1091 - acc: 0.8796 - val_loss: 0.1401 - val_acc: 0.8235\n",
      "Epoch 202/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1072 - acc: 0.8743 - val_loss: 0.1421 - val_acc: 0.8235\n",
      "Epoch 203/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1083 - acc: 0.8691 - val_loss: 0.1412 - val_acc: 0.8235\n",
      "Epoch 204/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1060 - acc: 0.8743 - val_loss: 0.1406 - val_acc: 0.8235\n",
      "Epoch 205/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1062 - acc: 0.8743 - val_loss: 0.1439 - val_acc: 0.8529\n",
      "Epoch 206/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1067 - acc: 0.8743 - val_loss: 0.1406 - val_acc: 0.8235\n",
      "Epoch 207/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.1049 - acc: 0.8743 - val_loss: 0.1398 - val_acc: 0.8235\n",
      "Epoch 208/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1052 - acc: 0.8691 - val_loss: 0.1423 - val_acc: 0.8235\n",
      "Epoch 209/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1052 - acc: 0.8743 - val_loss: 0.1410 - val_acc: 0.8235\n",
      "Epoch 210/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.1050 - acc: 0.8953 - val_loss: 0.1406 - val_acc: 0.8235\n",
      "Epoch 211/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1042 - acc: 0.8691 - val_loss: 0.1431 - val_acc: 0.8235\n",
      "Epoch 212/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1055 - acc: 0.8953 - val_loss: 0.1373 - val_acc: 0.8529\n",
      "Epoch 213/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1053 - acc: 0.8691 - val_loss: 0.1422 - val_acc: 0.7941\n",
      "Epoch 214/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.1054 - acc: 0.8901 - val_loss: 0.1423 - val_acc: 0.8529\n",
      "Epoch 215/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1042 - acc: 0.8796 - val_loss: 0.1396 - val_acc: 0.8235\n",
      "Epoch 216/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1029 - acc: 0.8953 - val_loss: 0.1394 - val_acc: 0.8235\n",
      "Epoch 217/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.1019 - acc: 0.8848 - val_loss: 0.1422 - val_acc: 0.8235\n",
      "Epoch 218/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1019 - acc: 0.8796 - val_loss: 0.1418 - val_acc: 0.8235\n",
      "Epoch 219/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.1011 - acc: 0.8901 - val_loss: 0.1383 - val_acc: 0.8235\n",
      "Epoch 220/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1010 - acc: 0.8848 - val_loss: 0.1411 - val_acc: 0.8235\n",
      "Epoch 221/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1004 - acc: 0.8901 - val_loss: 0.1405 - val_acc: 0.8235\n",
      "Epoch 222/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1001 - acc: 0.8901 - val_loss: 0.1395 - val_acc: 0.8235\n",
      "Epoch 223/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0998 - acc: 0.8796 - val_loss: 0.1417 - val_acc: 0.8235\n",
      "Epoch 224/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0993 - acc: 0.8953 - val_loss: 0.1384 - val_acc: 0.8235\n",
      "Epoch 225/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0994 - acc: 0.8848 - val_loss: 0.1416 - val_acc: 0.8235\n",
      "Epoch 226/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0989 - acc: 0.8953 - val_loss: 0.1383 - val_acc: 0.8529\n",
      "Epoch 227/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0993 - acc: 0.8848 - val_loss: 0.1429 - val_acc: 0.8235\n",
      "Epoch 228/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0991 - acc: 0.8953 - val_loss: 0.1359 - val_acc: 0.8529\n",
      "Epoch 229/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.1001 - acc: 0.8848 - val_loss: 0.1432 - val_acc: 0.7941\n",
      "Epoch 230/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.1006 - acc: 0.8953 - val_loss: 0.1350 - val_acc: 0.8529\n",
      "Epoch 231/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.1026 - acc: 0.8796 - val_loss: 0.1435 - val_acc: 0.7941\n",
      "Epoch 232/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.1006 - acc: 0.8901 - val_loss: 0.1366 - val_acc: 0.8529\n",
      "Epoch 233/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0986 - acc: 0.8848 - val_loss: 0.1363 - val_acc: 0.8235\n",
      "Epoch 234/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0967 - acc: 0.8953 - val_loss: 0.1408 - val_acc: 0.8235\n",
      "Epoch 235/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0969 - acc: 0.9005 - val_loss: 0.1359 - val_acc: 0.8529\n",
      "Epoch 236/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0982 - acc: 0.8848 - val_loss: 0.1436 - val_acc: 0.7941\n",
      "Epoch 237/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0973 - acc: 0.8953 - val_loss: 0.1342 - val_acc: 0.8235\n",
      "Epoch 238/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0966 - acc: 0.8848 - val_loss: 0.1375 - val_acc: 0.8235\n",
      "Epoch 239/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0953 - acc: 0.9005 - val_loss: 0.1404 - val_acc: 0.8235\n",
      "Epoch 240/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0949 - acc: 0.9005 - val_loss: 0.1378 - val_acc: 0.8235\n",
      "Epoch 241/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0947 - acc: 0.8953 - val_loss: 0.1400 - val_acc: 0.8235\n",
      "Epoch 242/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0946 - acc: 0.9005 - val_loss: 0.1343 - val_acc: 0.8235\n",
      "Epoch 243/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0945 - acc: 0.8901 - val_loss: 0.1401 - val_acc: 0.7941\n",
      "Epoch 244/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0939 - acc: 0.9005 - val_loss: 0.1378 - val_acc: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0936 - acc: 0.9005 - val_loss: 0.1388 - val_acc: 0.7941\n",
      "Epoch 246/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0927 - acc: 0.9005 - val_loss: 0.1366 - val_acc: 0.8235\n",
      "Epoch 247/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0926 - acc: 0.9005 - val_loss: 0.1369 - val_acc: 0.8235\n",
      "Epoch 248/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0922 - acc: 0.9005 - val_loss: 0.1397 - val_acc: 0.7941\n",
      "Epoch 249/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0924 - acc: 0.9005 - val_loss: 0.1353 - val_acc: 0.8235\n",
      "Epoch 250/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0923 - acc: 0.8953 - val_loss: 0.1396 - val_acc: 0.7941\n",
      "Epoch 251/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0922 - acc: 0.9005 - val_loss: 0.1335 - val_acc: 0.8235\n",
      "Epoch 252/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.0922 - acc: 0.8901 - val_loss: 0.1396 - val_acc: 0.7941\n",
      "Epoch 253/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0918 - acc: 0.9005 - val_loss: 0.1364 - val_acc: 0.8529\n",
      "Epoch 254/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0916 - acc: 0.8953 - val_loss: 0.1385 - val_acc: 0.7941\n",
      "Epoch 255/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0906 - acc: 0.9058 - val_loss: 0.1337 - val_acc: 0.8235\n",
      "Epoch 256/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0905 - acc: 0.8953 - val_loss: 0.1383 - val_acc: 0.8235\n",
      "Epoch 257/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0896 - acc: 0.9005 - val_loss: 0.1383 - val_acc: 0.8235\n",
      "Epoch 258/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0896 - acc: 0.9005 - val_loss: 0.1361 - val_acc: 0.8235\n",
      "Epoch 259/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.0891 - acc: 0.9005 - val_loss: 0.1365 - val_acc: 0.8235\n",
      "Epoch 260/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0890 - acc: 0.9005 - val_loss: 0.1350 - val_acc: 0.8235\n",
      "Epoch 261/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0890 - acc: 0.9005 - val_loss: 0.1411 - val_acc: 0.7941\n",
      "Epoch 262/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0891 - acc: 0.9058 - val_loss: 0.1319 - val_acc: 0.8529\n",
      "Epoch 263/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0899 - acc: 0.8953 - val_loss: 0.1399 - val_acc: 0.7941\n",
      "Epoch 264/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0902 - acc: 0.9058 - val_loss: 0.1313 - val_acc: 0.8529\n",
      "Epoch 265/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.0913 - acc: 0.8953 - val_loss: 0.1413 - val_acc: 0.7941\n",
      "Epoch 266/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0912 - acc: 0.8953 - val_loss: 0.1301 - val_acc: 0.8529\n",
      "Epoch 267/500\n",
      "191/191 [==============================] - 0s 16us/step - loss: 0.0913 - acc: 0.8953 - val_loss: 0.1399 - val_acc: 0.7941\n",
      "Epoch 268/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0894 - acc: 0.9058 - val_loss: 0.1335 - val_acc: 0.8235\n",
      "Epoch 269/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0882 - acc: 0.9005 - val_loss: 0.1361 - val_acc: 0.8235\n",
      "Epoch 270/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0869 - acc: 0.9058 - val_loss: 0.1410 - val_acc: 0.8235\n",
      "Epoch 271/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0885 - acc: 0.9058 - val_loss: 0.1301 - val_acc: 0.8529\n",
      "Epoch 272/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0892 - acc: 0.8953 - val_loss: 0.1392 - val_acc: 0.7941\n",
      "Epoch 273/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0890 - acc: 0.9005 - val_loss: 0.1349 - val_acc: 0.8529\n",
      "Epoch 274/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0877 - acc: 0.9058 - val_loss: 0.1361 - val_acc: 0.8235\n",
      "Epoch 275/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0859 - acc: 0.9058 - val_loss: 0.1391 - val_acc: 0.7941\n",
      "Epoch 276/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0860 - acc: 0.9058 - val_loss: 0.1341 - val_acc: 0.8529\n",
      "Epoch 277/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0874 - acc: 0.8953 - val_loss: 0.1386 - val_acc: 0.7941\n",
      "Epoch 278/500\n",
      "191/191 [==============================] - 0s 74us/step - loss: 0.0867 - acc: 0.9058 - val_loss: 0.1329 - val_acc: 0.8235\n",
      "Epoch 279/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0858 - acc: 0.9005 - val_loss: 0.1421 - val_acc: 0.7941\n",
      "Epoch 280/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0853 - acc: 0.9058 - val_loss: 0.1357 - val_acc: 0.8235\n",
      "Epoch 281/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.0850 - acc: 0.9058 - val_loss: 0.1344 - val_acc: 0.8235\n",
      "Epoch 282/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0843 - acc: 0.9005 - val_loss: 0.1432 - val_acc: 0.7647\n",
      "Epoch 283/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0850 - acc: 0.9110 - val_loss: 0.1329 - val_acc: 0.8235\n",
      "Epoch 284/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0854 - acc: 0.9058 - val_loss: 0.1403 - val_acc: 0.7941\n",
      "Epoch 285/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0841 - acc: 0.9110 - val_loss: 0.1374 - val_acc: 0.8235\n",
      "Epoch 286/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0834 - acc: 0.9005 - val_loss: 0.1359 - val_acc: 0.8235\n",
      "Epoch 287/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0837 - acc: 0.9058 - val_loss: 0.1418 - val_acc: 0.7647\n",
      "Epoch 288/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0833 - acc: 0.9110 - val_loss: 0.1340 - val_acc: 0.8235\n",
      "Epoch 289/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0833 - acc: 0.9005 - val_loss: 0.1412 - val_acc: 0.7941\n",
      "Epoch 290/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0835 - acc: 0.9110 - val_loss: 0.1344 - val_acc: 0.8529\n",
      "Epoch 291/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0829 - acc: 0.9005 - val_loss: 0.1411 - val_acc: 0.7647\n",
      "Epoch 292/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0824 - acc: 0.9110 - val_loss: 0.1364 - val_acc: 0.8235\n",
      "Epoch 293/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0821 - acc: 0.9058 - val_loss: 0.1393 - val_acc: 0.7941\n",
      "Epoch 294/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0818 - acc: 0.9110 - val_loss: 0.1372 - val_acc: 0.7941\n",
      "Epoch 295/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0815 - acc: 0.9058 - val_loss: 0.1375 - val_acc: 0.8235\n",
      "Epoch 296/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0812 - acc: 0.9058 - val_loss: 0.1420 - val_acc: 0.7647\n",
      "Epoch 297/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0813 - acc: 0.9110 - val_loss: 0.1349 - val_acc: 0.8235\n",
      "Epoch 298/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0812 - acc: 0.9058 - val_loss: 0.1410 - val_acc: 0.7647\n",
      "Epoch 299/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0809 - acc: 0.9110 - val_loss: 0.1363 - val_acc: 0.8235\n",
      "Epoch 300/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0808 - acc: 0.9058 - val_loss: 0.1416 - val_acc: 0.7647\n",
      "Epoch 301/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0806 - acc: 0.9110 - val_loss: 0.1360 - val_acc: 0.8235\n",
      "Epoch 302/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0803 - acc: 0.9058 - val_loss: 0.1407 - val_acc: 0.7647\n",
      "Epoch 303/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0799 - acc: 0.9110 - val_loss: 0.1374 - val_acc: 0.7941\n",
      "Epoch 304/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0798 - acc: 0.9058 - val_loss: 0.1398 - val_acc: 0.7647\n",
      "Epoch 305/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0796 - acc: 0.9110 - val_loss: 0.1382 - val_acc: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0793 - acc: 0.9110 - val_loss: 0.1394 - val_acc: 0.7647\n",
      "Epoch 307/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0791 - acc: 0.9110 - val_loss: 0.1385 - val_acc: 0.7941\n",
      "Epoch 308/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0789 - acc: 0.9110 - val_loss: 0.1384 - val_acc: 0.7941\n",
      "Epoch 309/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0787 - acc: 0.9110 - val_loss: 0.1399 - val_acc: 0.7647\n",
      "Epoch 310/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0785 - acc: 0.9110 - val_loss: 0.1382 - val_acc: 0.7941\n",
      "Epoch 311/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0784 - acc: 0.9110 - val_loss: 0.1396 - val_acc: 0.7647\n",
      "Epoch 312/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0782 - acc: 0.9110 - val_loss: 0.1374 - val_acc: 0.7647\n",
      "Epoch 313/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0780 - acc: 0.9110 - val_loss: 0.1416 - val_acc: 0.7647\n",
      "Epoch 314/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0779 - acc: 0.9110 - val_loss: 0.1358 - val_acc: 0.7941\n",
      "Epoch 315/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0779 - acc: 0.9110 - val_loss: 0.1436 - val_acc: 0.7647\n",
      "Epoch 316/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0779 - acc: 0.9110 - val_loss: 0.1327 - val_acc: 0.8235\n",
      "Epoch 317/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0785 - acc: 0.9058 - val_loss: 0.1483 - val_acc: 0.7353\n",
      "Epoch 318/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0791 - acc: 0.9162 - val_loss: 0.1288 - val_acc: 0.8529\n",
      "Epoch 319/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.0807 - acc: 0.9005 - val_loss: 0.1489 - val_acc: 0.7353\n",
      "Epoch 320/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0798 - acc: 0.9162 - val_loss: 0.1308 - val_acc: 0.8529\n",
      "Epoch 321/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0790 - acc: 0.9005 - val_loss: 0.1445 - val_acc: 0.7647\n",
      "Epoch 322/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0771 - acc: 0.9110 - val_loss: 0.1387 - val_acc: 0.7647\n",
      "Epoch 323/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0762 - acc: 0.9110 - val_loss: 0.1367 - val_acc: 0.7941\n",
      "Epoch 324/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0763 - acc: 0.9110 - val_loss: 0.1440 - val_acc: 0.7647\n",
      "Epoch 325/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.0768 - acc: 0.9162 - val_loss: 0.1320 - val_acc: 0.8235\n",
      "Epoch 326/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0772 - acc: 0.9058 - val_loss: 0.1464 - val_acc: 0.7647\n",
      "Epoch 327/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0765 - acc: 0.9162 - val_loss: 0.1351 - val_acc: 0.8235\n",
      "Epoch 328/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.0759 - acc: 0.9110 - val_loss: 0.1404 - val_acc: 0.7647\n",
      "Epoch 329/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0752 - acc: 0.9110 - val_loss: 0.1394 - val_acc: 0.7647\n",
      "Epoch 330/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0750 - acc: 0.9110 - val_loss: 0.1363 - val_acc: 0.7647\n",
      "Epoch 331/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0750 - acc: 0.9110 - val_loss: 0.1436 - val_acc: 0.7647\n",
      "Epoch 332/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0751 - acc: 0.9162 - val_loss: 0.1345 - val_acc: 0.8235\n",
      "Epoch 333/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0751 - acc: 0.9110 - val_loss: 0.1430 - val_acc: 0.7647\n",
      "Epoch 334/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0748 - acc: 0.9162 - val_loss: 0.1360 - val_acc: 0.7941\n",
      "Epoch 335/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0743 - acc: 0.9110 - val_loss: 0.1399 - val_acc: 0.7647\n",
      "Epoch 336/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0740 - acc: 0.9110 - val_loss: 0.1404 - val_acc: 0.7647\n",
      "Epoch 337/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0738 - acc: 0.9110 - val_loss: 0.1362 - val_acc: 0.7941\n",
      "Epoch 338/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0738 - acc: 0.9110 - val_loss: 0.1417 - val_acc: 0.7647\n",
      "Epoch 339/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0738 - acc: 0.9162 - val_loss: 0.1349 - val_acc: 0.7647\n",
      "Epoch 340/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0738 - acc: 0.9110 - val_loss: 0.1429 - val_acc: 0.7647\n",
      "Epoch 341/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0735 - acc: 0.9162 - val_loss: 0.1350 - val_acc: 0.7647\n",
      "Epoch 342/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0733 - acc: 0.9110 - val_loss: 0.1409 - val_acc: 0.7647\n",
      "Epoch 343/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0731 - acc: 0.9215 - val_loss: 0.1361 - val_acc: 0.7647\n",
      "Epoch 344/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0728 - acc: 0.9162 - val_loss: 0.1394 - val_acc: 0.7647\n",
      "Epoch 345/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0725 - acc: 0.9162 - val_loss: 0.1383 - val_acc: 0.7647\n",
      "Epoch 346/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0723 - acc: 0.9162 - val_loss: 0.1374 - val_acc: 0.7647\n",
      "Epoch 347/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0722 - acc: 0.9162 - val_loss: 0.1395 - val_acc: 0.7647\n",
      "Epoch 348/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0720 - acc: 0.9215 - val_loss: 0.1365 - val_acc: 0.7647\n",
      "Epoch 349/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0719 - acc: 0.9162 - val_loss: 0.1414 - val_acc: 0.7647\n",
      "Epoch 350/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0719 - acc: 0.9215 - val_loss: 0.1347 - val_acc: 0.7647\n",
      "Epoch 351/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0719 - acc: 0.9162 - val_loss: 0.1435 - val_acc: 0.7647\n",
      "Epoch 352/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0719 - acc: 0.9215 - val_loss: 0.1324 - val_acc: 0.8235\n",
      "Epoch 353/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0723 - acc: 0.9162 - val_loss: 0.1471 - val_acc: 0.7353\n",
      "Epoch 354/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0726 - acc: 0.9215 - val_loss: 0.1296 - val_acc: 0.8235\n",
      "Epoch 355/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0736 - acc: 0.9110 - val_loss: 0.1479 - val_acc: 0.7353\n",
      "Epoch 356/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0728 - acc: 0.9215 - val_loss: 0.1305 - val_acc: 0.8235\n",
      "Epoch 357/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0724 - acc: 0.9162 - val_loss: 0.1438 - val_acc: 0.7647\n",
      "Epoch 358/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0710 - acc: 0.9215 - val_loss: 0.1366 - val_acc: 0.7647\n",
      "Epoch 359/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0703 - acc: 0.9162 - val_loss: 0.1373 - val_acc: 0.7647\n",
      "Epoch 360/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0701 - acc: 0.9215 - val_loss: 0.1412 - val_acc: 0.7647\n",
      "Epoch 361/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0702 - acc: 0.9215 - val_loss: 0.1332 - val_acc: 0.7647\n",
      "Epoch 362/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0705 - acc: 0.9162 - val_loss: 0.1454 - val_acc: 0.7647\n",
      "Epoch 363/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0707 - acc: 0.9215 - val_loss: 0.1310 - val_acc: 0.7941\n",
      "Epoch 364/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0712 - acc: 0.9162 - val_loss: 0.1453 - val_acc: 0.7647\n",
      "Epoch 365/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0707 - acc: 0.9215 - val_loss: 0.1314 - val_acc: 0.8235\n",
      "Epoch 366/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0704 - acc: 0.9162 - val_loss: 0.1422 - val_acc: 0.7647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0695 - acc: 0.9215 - val_loss: 0.1357 - val_acc: 0.7647\n",
      "Epoch 368/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0690 - acc: 0.9162 - val_loss: 0.1367 - val_acc: 0.7941\n",
      "Epoch 369/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0687 - acc: 0.9215 - val_loss: 0.1395 - val_acc: 0.7941\n",
      "Epoch 370/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0688 - acc: 0.9215 - val_loss: 0.1333 - val_acc: 0.7941\n",
      "Epoch 371/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0689 - acc: 0.9162 - val_loss: 0.1423 - val_acc: 0.7941\n",
      "Epoch 372/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0689 - acc: 0.9215 - val_loss: 0.1325 - val_acc: 0.8235\n",
      "Epoch 373/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0688 - acc: 0.9162 - val_loss: 0.1415 - val_acc: 0.7941\n",
      "Epoch 374/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0685 - acc: 0.9215 - val_loss: 0.1326 - val_acc: 0.7941\n",
      "Epoch 375/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0683 - acc: 0.9162 - val_loss: 0.1394 - val_acc: 0.7941\n",
      "Epoch 376/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0679 - acc: 0.9215 - val_loss: 0.1349 - val_acc: 0.7941\n",
      "Epoch 377/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0676 - acc: 0.9162 - val_loss: 0.1365 - val_acc: 0.7941\n",
      "Epoch 378/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0674 - acc: 0.9215 - val_loss: 0.1360 - val_acc: 0.7941\n",
      "Epoch 379/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0672 - acc: 0.9215 - val_loss: 0.1339 - val_acc: 0.7941\n",
      "Epoch 380/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0671 - acc: 0.9215 - val_loss: 0.1378 - val_acc: 0.7941\n",
      "Epoch 381/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0670 - acc: 0.9215 - val_loss: 0.1325 - val_acc: 0.7941\n",
      "Epoch 382/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0670 - acc: 0.9162 - val_loss: 0.1381 - val_acc: 0.7941\n",
      "Epoch 383/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0669 - acc: 0.9215 - val_loss: 0.1310 - val_acc: 0.7941\n",
      "Epoch 384/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0668 - acc: 0.9162 - val_loss: 0.1385 - val_acc: 0.7941\n",
      "Epoch 385/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0667 - acc: 0.9215 - val_loss: 0.1306 - val_acc: 0.8235\n",
      "Epoch 386/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0666 - acc: 0.9162 - val_loss: 0.1389 - val_acc: 0.7941\n",
      "Epoch 387/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0664 - acc: 0.9215 - val_loss: 0.1294 - val_acc: 0.8235\n",
      "Epoch 388/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0664 - acc: 0.9162 - val_loss: 0.1391 - val_acc: 0.7941\n",
      "Epoch 389/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0662 - acc: 0.9162 - val_loss: 0.1292 - val_acc: 0.8529\n",
      "Epoch 390/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0661 - acc: 0.9162 - val_loss: 0.1392 - val_acc: 0.7941\n",
      "Epoch 391/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0659 - acc: 0.9162 - val_loss: 0.1288 - val_acc: 0.8235\n",
      "Epoch 392/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0657 - acc: 0.9162 - val_loss: 0.1383 - val_acc: 0.7941\n",
      "Epoch 393/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0654 - acc: 0.9162 - val_loss: 0.1293 - val_acc: 0.8529\n",
      "Epoch 394/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0652 - acc: 0.9215 - val_loss: 0.1372 - val_acc: 0.7941\n",
      "Epoch 395/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0649 - acc: 0.9162 - val_loss: 0.1295 - val_acc: 0.8235\n",
      "Epoch 396/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0646 - acc: 0.9215 - val_loss: 0.1361 - val_acc: 0.7941\n",
      "Epoch 397/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0644 - acc: 0.9162 - val_loss: 0.1294 - val_acc: 0.8235\n",
      "Epoch 398/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0642 - acc: 0.9215 - val_loss: 0.1360 - val_acc: 0.7941\n",
      "Epoch 399/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0641 - acc: 0.9162 - val_loss: 0.1285 - val_acc: 0.8529\n",
      "Epoch 400/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0640 - acc: 0.9215 - val_loss: 0.1372 - val_acc: 0.7941\n",
      "Epoch 401/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.0640 - acc: 0.9162 - val_loss: 0.1267 - val_acc: 0.8529\n",
      "Epoch 402/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0641 - acc: 0.9162 - val_loss: 0.1404 - val_acc: 0.7941\n",
      "Epoch 403/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0644 - acc: 0.9162 - val_loss: 0.1250 - val_acc: 0.8529\n",
      "Epoch 404/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0650 - acc: 0.9162 - val_loss: 0.1442 - val_acc: 0.7941\n",
      "Epoch 405/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0655 - acc: 0.9215 - val_loss: 0.1240 - val_acc: 0.8824\n",
      "Epoch 406/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0654 - acc: 0.9162 - val_loss: 0.1408 - val_acc: 0.7941\n",
      "Epoch 407/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0637 - acc: 0.9215 - val_loss: 0.1306 - val_acc: 0.8529\n",
      "Epoch 408/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0630 - acc: 0.9162 - val_loss: 0.1324 - val_acc: 0.7941\n",
      "Epoch 409/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0625 - acc: 0.9162 - val_loss: 0.1349 - val_acc: 0.7941\n",
      "Epoch 410/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0625 - acc: 0.9162 - val_loss: 0.1292 - val_acc: 0.8235\n",
      "Epoch 411/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0623 - acc: 0.9162 - val_loss: 0.1367 - val_acc: 0.7941\n",
      "Epoch 412/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0622 - acc: 0.9162 - val_loss: 0.1272 - val_acc: 0.8529\n",
      "Epoch 413/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0620 - acc: 0.9162 - val_loss: 0.1346 - val_acc: 0.7941\n",
      "Epoch 414/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0619 - acc: 0.9215 - val_loss: 0.1282 - val_acc: 0.8235\n",
      "Epoch 415/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0614 - acc: 0.9162 - val_loss: 0.1334 - val_acc: 0.7941\n",
      "Epoch 416/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0612 - acc: 0.9162 - val_loss: 0.1284 - val_acc: 0.8235\n",
      "Epoch 417/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0609 - acc: 0.9162 - val_loss: 0.1310 - val_acc: 0.7941\n",
      "Epoch 418/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0608 - acc: 0.9267 - val_loss: 0.1296 - val_acc: 0.8235\n",
      "Epoch 419/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0605 - acc: 0.9162 - val_loss: 0.1308 - val_acc: 0.7941\n",
      "Epoch 420/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0604 - acc: 0.9267 - val_loss: 0.1298 - val_acc: 0.7941\n",
      "Epoch 421/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0602 - acc: 0.9267 - val_loss: 0.1291 - val_acc: 0.7941\n",
      "Epoch 422/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0601 - acc: 0.9267 - val_loss: 0.1309 - val_acc: 0.7941\n",
      "Epoch 423/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0599 - acc: 0.9267 - val_loss: 0.1283 - val_acc: 0.8235\n",
      "Epoch 424/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0598 - acc: 0.9267 - val_loss: 0.1315 - val_acc: 0.7941\n",
      "Epoch 425/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0598 - acc: 0.9372 - val_loss: 0.1264 - val_acc: 0.8235\n",
      "Epoch 426/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0598 - acc: 0.9267 - val_loss: 0.1361 - val_acc: 0.7941\n",
      "Epoch 427/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0603 - acc: 0.9476 - val_loss: 0.1223 - val_acc: 0.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0620 - acc: 0.9110 - val_loss: 0.1485 - val_acc: 0.7647\n",
      "Epoch 429/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0650 - acc: 0.9372 - val_loss: 0.1186 - val_acc: 0.8824\n",
      "Epoch 430/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0664 - acc: 0.9005 - val_loss: 0.1460 - val_acc: 0.7941\n",
      "Epoch 431/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0630 - acc: 0.9424 - val_loss: 0.1283 - val_acc: 0.8235\n",
      "Epoch 432/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0603 - acc: 0.9267 - val_loss: 0.1274 - val_acc: 0.8235\n",
      "Epoch 433/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0595 - acc: 0.9319 - val_loss: 0.1407 - val_acc: 0.7941\n",
      "Epoch 434/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0608 - acc: 0.9372 - val_loss: 0.1264 - val_acc: 0.8529\n",
      "Epoch 435/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0609 - acc: 0.9215 - val_loss: 0.1351 - val_acc: 0.7941\n",
      "Epoch 436/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0596 - acc: 0.9476 - val_loss: 0.1283 - val_acc: 0.7941\n",
      "Epoch 437/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0591 - acc: 0.9372 - val_loss: 0.1268 - val_acc: 0.8235\n",
      "Epoch 438/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0590 - acc: 0.9215 - val_loss: 0.1417 - val_acc: 0.7941\n",
      "Epoch 439/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0615 - acc: 0.9476 - val_loss: 0.1196 - val_acc: 0.8824\n",
      "Epoch 440/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0625 - acc: 0.9058 - val_loss: 0.1424 - val_acc: 0.7941\n",
      "Epoch 441/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0611 - acc: 0.9424 - val_loss: 0.1277 - val_acc: 0.8235\n",
      "Epoch 442/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0591 - acc: 0.9267 - val_loss: 0.1259 - val_acc: 0.7941\n",
      "Epoch 443/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0583 - acc: 0.9319 - val_loss: 0.1379 - val_acc: 0.7941\n",
      "Epoch 444/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0592 - acc: 0.9372 - val_loss: 0.1265 - val_acc: 0.8235\n",
      "Epoch 445/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0581 - acc: 0.9267 - val_loss: 0.1319 - val_acc: 0.7941\n",
      "Epoch 446/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0573 - acc: 0.9372 - val_loss: 0.1297 - val_acc: 0.7941\n",
      "Epoch 447/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0569 - acc: 0.9424 - val_loss: 0.1254 - val_acc: 0.8235\n",
      "Epoch 448/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0572 - acc: 0.9319 - val_loss: 0.1346 - val_acc: 0.7941\n",
      "Epoch 449/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0575 - acc: 0.9476 - val_loss: 0.1239 - val_acc: 0.8529\n",
      "Epoch 450/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.0572 - acc: 0.9319 - val_loss: 0.1312 - val_acc: 0.7941\n",
      "Epoch 451/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0569 - acc: 0.9476 - val_loss: 0.1268 - val_acc: 0.8235\n",
      "Epoch 452/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0561 - acc: 0.9372 - val_loss: 0.1271 - val_acc: 0.8235\n",
      "Epoch 453/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0562 - acc: 0.9372 - val_loss: 0.1321 - val_acc: 0.7941\n",
      "Epoch 454/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0566 - acc: 0.9476 - val_loss: 0.1230 - val_acc: 0.8235\n",
      "Epoch 455/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0568 - acc: 0.9319 - val_loss: 0.1330 - val_acc: 0.7941\n",
      "Epoch 456/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.0562 - acc: 0.9476 - val_loss: 0.1271 - val_acc: 0.8235\n",
      "Epoch 457/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0557 - acc: 0.9424 - val_loss: 0.1257 - val_acc: 0.7941\n",
      "Epoch 458/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0555 - acc: 0.9476 - val_loss: 0.1291 - val_acc: 0.7941\n",
      "Epoch 459/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0554 - acc: 0.9476 - val_loss: 0.1264 - val_acc: 0.8235\n",
      "Epoch 460/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0555 - acc: 0.9424 - val_loss: 0.1299 - val_acc: 0.7941\n",
      "Epoch 461/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0557 - acc: 0.9476 - val_loss: 0.1221 - val_acc: 0.8235\n",
      "Epoch 462/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0555 - acc: 0.9372 - val_loss: 0.1306 - val_acc: 0.7941\n",
      "Epoch 463/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.0553 - acc: 0.9529 - val_loss: 0.1257 - val_acc: 0.8235\n",
      "Epoch 464/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0549 - acc: 0.9424 - val_loss: 0.1254 - val_acc: 0.7941\n",
      "Epoch 465/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.0547 - acc: 0.9424 - val_loss: 0.1259 - val_acc: 0.7941\n",
      "Epoch 466/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0546 - acc: 0.9476 - val_loss: 0.1265 - val_acc: 0.7941\n",
      "Epoch 467/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0544 - acc: 0.9476 - val_loss: 0.1277 - val_acc: 0.7941\n",
      "Epoch 468/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0545 - acc: 0.9476 - val_loss: 0.1233 - val_acc: 0.8235\n",
      "Epoch 469/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0545 - acc: 0.9424 - val_loss: 0.1305 - val_acc: 0.7941\n",
      "Epoch 470/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0547 - acc: 0.9529 - val_loss: 0.1236 - val_acc: 0.8235\n",
      "Epoch 471/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0546 - acc: 0.9372 - val_loss: 0.1300 - val_acc: 0.7941\n",
      "Epoch 472/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0545 - acc: 0.9529 - val_loss: 0.1237 - val_acc: 0.7941\n",
      "Epoch 473/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0541 - acc: 0.9424 - val_loss: 0.1272 - val_acc: 0.7941\n",
      "Epoch 474/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0537 - acc: 0.9476 - val_loss: 0.1262 - val_acc: 0.7941\n",
      "Epoch 475/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0535 - acc: 0.9476 - val_loss: 0.1251 - val_acc: 0.7941\n",
      "Epoch 476/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0534 - acc: 0.9476 - val_loss: 0.1266 - val_acc: 0.7941\n",
      "Epoch 477/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0535 - acc: 0.9529 - val_loss: 0.1220 - val_acc: 0.8529\n",
      "Epoch 478/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.0537 - acc: 0.9424 - val_loss: 0.1300 - val_acc: 0.7941\n",
      "Epoch 479/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0538 - acc: 0.9529 - val_loss: 0.1217 - val_acc: 0.8235\n",
      "Epoch 480/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0538 - acc: 0.9372 - val_loss: 0.1288 - val_acc: 0.7941\n",
      "Epoch 481/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0539 - acc: 0.9529 - val_loss: 0.1222 - val_acc: 0.8235\n",
      "Epoch 482/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0530 - acc: 0.9476 - val_loss: 0.1268 - val_acc: 0.7941\n",
      "Epoch 483/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0527 - acc: 0.9476 - val_loss: 0.1268 - val_acc: 0.7941\n",
      "Epoch 484/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0526 - acc: 0.9529 - val_loss: 0.1211 - val_acc: 0.8529\n",
      "Epoch 485/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0530 - acc: 0.9476 - val_loss: 0.1298 - val_acc: 0.7941\n",
      "Epoch 486/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0532 - acc: 0.9529 - val_loss: 0.1225 - val_acc: 0.8235\n",
      "Epoch 487/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0528 - acc: 0.9424 - val_loss: 0.1268 - val_acc: 0.7941\n",
      "Epoch 488/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.0525 - acc: 0.9529 - val_loss: 0.1228 - val_acc: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0520 - acc: 0.9476 - val_loss: 0.1245 - val_acc: 0.7941\n",
      "Epoch 490/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0518 - acc: 0.9476 - val_loss: 0.1259 - val_acc: 0.7941\n",
      "Epoch 491/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0519 - acc: 0.9476 - val_loss: 0.1214 - val_acc: 0.8235\n",
      "Epoch 492/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0520 - acc: 0.9476 - val_loss: 0.1276 - val_acc: 0.7941\n",
      "Epoch 493/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0523 - acc: 0.9529 - val_loss: 0.1214 - val_acc: 0.8235\n",
      "Epoch 494/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.0521 - acc: 0.9476 - val_loss: 0.1278 - val_acc: 0.7941\n",
      "Epoch 495/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0520 - acc: 0.9529 - val_loss: 0.1221 - val_acc: 0.8235\n",
      "Epoch 496/500\n",
      "191/191 [==============================] - 0s 21us/step - loss: 0.0515 - acc: 0.9476 - val_loss: 0.1245 - val_acc: 0.7941\n",
      "Epoch 497/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.0512 - acc: 0.9529 - val_loss: 0.1246 - val_acc: 0.7941\n",
      "Epoch 498/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 0.0511 - acc: 0.9476 - val_loss: 0.1230 - val_acc: 0.8235\n",
      "Epoch 499/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.0511 - acc: 0.9476 - val_loss: 0.1256 - val_acc: 0.7941\n",
      "Epoch 500/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.0512 - acc: 0.9581 - val_loss: 0.1209 - val_acc: 0.8235\n"
     ]
    }
   ],
   "source": [
    "# use the training data to fit the model.  Choose numbers for epochs and the validation split\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=500,\n",
    "                    validation_split=0.15,\n",
    "                    batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24478852240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check losses for overfitting and performance\n",
    "plt.plot(history.history['loss'], label = 'training loss')\n",
    "plt.plot(history.history['val_loss'], label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy for overfitting and performance\n",
    "# create the plots similary as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 80us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.061694176656504472, 0.92888888888888888]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how we get the [loss, accuracy]\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 123us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10856690218574122, 0.85964911130436683]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model.evaluate on the test set to see performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (bonus) next step: use dropout and/or regularization to prevent overfitting.  Dropout goes after dense layers.  The standard dropout rate is 0.5.  Example:\n",
    "\n",
    "```python\n",
    "x1 = Dense(10)(inputs)\n",
    "x2 = Dropout(0.5)(x1)\n",
    "preds = Dense(1, activation='sigmoid')(x2)\n",
    "```\n",
    "\n",
    "0.5 means half of the connections between x1 and the preds layer are dropped (ignored) during training.  0.1 would mean 10% of the connections would be dropped during training.  For such as small net as we have, the range of 0.1-0.3 makes more sense.\n",
    "\n",
    "https://keras.io/layers/core/#dropout\n",
    "\n",
    "https://keras.io/regularizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "inputs = Input(shape=(features.shape[1], ))\n",
    "x1 = Dense(300, activation='elu')(inputs)\n",
    "x2 = Dropout(0.1)(x1)\n",
    "x3 = Dense(50, activation='elu')(x2)\n",
    "predictions = Dense(1, activation='sigmoid')(x3)\n",
    "\n",
    "model = Model(inputs, predictions)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191 samples, validate on 34 samples\n",
      "Epoch 1/500\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 8.8273 - acc: 0.4450 - val_loss: 5.0719 - val_acc: 0.4412\n",
      "Epoch 2/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 4.8494 - acc: 0.4712 - val_loss: 4.0573 - val_acc: 0.5588\n",
      "Epoch 3/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 4.5439 - acc: 0.5026 - val_loss: 5.6753 - val_acc: 0.5588\n",
      "Epoch 4/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 4.8055 - acc: 0.5812 - val_loss: 3.1114 - val_acc: 0.5588\n",
      "Epoch 5/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 4.0064 - acc: 0.5236 - val_loss: 1.2342 - val_acc: 0.5294\n",
      "Epoch 6/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 2.5412 - acc: 0.5916 - val_loss: 3.1068 - val_acc: 0.5000\n",
      "Epoch 7/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 3.8758 - acc: 0.5079 - val_loss: 2.6216 - val_acc: 0.5294\n",
      "Epoch 8/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 2.8989 - acc: 0.6021 - val_loss: 1.0916 - val_acc: 0.5882\n",
      "Epoch 9/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 2.9037 - acc: 0.5236 - val_loss: 1.1245 - val_acc: 0.7647\n",
      "Epoch 10/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 2.6865 - acc: 0.5602 - val_loss: 1.7131 - val_acc: 0.7059\n",
      "Epoch 11/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 3.2434 - acc: 0.5864 - val_loss: 1.4589 - val_acc: 0.7353\n",
      "Epoch 12/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 2.6158 - acc: 0.5969 - val_loss: 0.9106 - val_acc: 0.7353\n",
      "Epoch 13/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.8260 - acc: 0.5707 - val_loss: 1.0454 - val_acc: 0.6471\n",
      "Epoch 14/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.3321 - acc: 0.6335 - val_loss: 1.3504 - val_acc: 0.6176\n",
      "Epoch 15/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 2.5860 - acc: 0.5497 - val_loss: 1.1685 - val_acc: 0.7059\n",
      "Epoch 16/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.7941 - acc: 0.5812 - val_loss: 0.8406 - val_acc: 0.7059\n",
      "Epoch 17/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 2.3703 - acc: 0.6387 - val_loss: 1.0224 - val_acc: 0.7941\n",
      "Epoch 18/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.7184 - acc: 0.6545 - val_loss: 1.3514 - val_acc: 0.7353\n",
      "Epoch 19/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.7106 - acc: 0.6230 - val_loss: 1.2898 - val_acc: 0.7647\n",
      "Epoch 20/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 2.1634 - acc: 0.6178 - val_loss: 0.9280 - val_acc: 0.7941\n",
      "Epoch 21/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.7266 - acc: 0.5916 - val_loss: 0.7428 - val_acc: 0.7353\n",
      "Epoch 22/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.2432 - acc: 0.5969 - val_loss: 0.8682 - val_acc: 0.7059\n",
      "Epoch 23/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 2.4540 - acc: 0.6021 - val_loss: 0.9003 - val_acc: 0.6765\n",
      "Epoch 24/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 2.3329 - acc: 0.6649 - val_loss: 0.7247 - val_acc: 0.7353\n",
      "Epoch 25/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.4060 - acc: 0.5812 - val_loss: 0.7155 - val_acc: 0.7353\n",
      "Epoch 26/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 2.6119 - acc: 0.5812 - val_loss: 0.8682 - val_acc: 0.7647\n",
      "Epoch 27/500\n",
      "191/191 [==============================] - 0s 26us/step - loss: 2.0663 - acc: 0.6126 - val_loss: 0.9261 - val_acc: 0.7647\n",
      "Epoch 28/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 2.0608 - acc: 0.6492 - val_loss: 0.7454 - val_acc: 0.8235\n",
      "Epoch 29/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.7627 - acc: 0.6963 - val_loss: 0.6374 - val_acc: 0.7647\n",
      "Epoch 30/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.0957 - acc: 0.6230 - val_loss: 0.6431 - val_acc: 0.7059\n",
      "Epoch 31/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 2.1011 - acc: 0.6597 - val_loss: 0.6634 - val_acc: 0.7059\n",
      "Epoch 32/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 1.7987 - acc: 0.6806 - val_loss: 0.6481 - val_acc: 0.6765\n",
      "Epoch 33/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 2.1436 - acc: 0.6021 - val_loss: 0.6296 - val_acc: 0.7941\n",
      "Epoch 34/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.5397 - acc: 0.6754 - val_loss: 0.6842 - val_acc: 0.8235\n",
      "Epoch 35/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.8075 - acc: 0.6178 - val_loss: 0.6231 - val_acc: 0.7941\n",
      "Epoch 36/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.9555 - acc: 0.6545 - val_loss: 0.5640 - val_acc: 0.7059\n",
      "Epoch 37/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.7832 - acc: 0.6387 - val_loss: 0.6282 - val_acc: 0.7353\n",
      "Epoch 38/500\n",
      "191/191 [==============================] - 0s 79us/step - loss: 2.1130 - acc: 0.5550 - val_loss: 0.5634 - val_acc: 0.7059\n",
      "Epoch 39/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.7005 - acc: 0.5969 - val_loss: 0.5514 - val_acc: 0.7941\n",
      "Epoch 40/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 2.0026 - acc: 0.5864 - val_loss: 0.6260 - val_acc: 0.8235\n",
      "Epoch 41/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 1.9425 - acc: 0.6335 - val_loss: 0.6219 - val_acc: 0.7941\n",
      "Epoch 42/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.9890 - acc: 0.6545 - val_loss: 0.5217 - val_acc: 0.7647\n",
      "Epoch 43/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 2.0310 - acc: 0.5550 - val_loss: 0.5329 - val_acc: 0.7059\n",
      "Epoch 44/500\n",
      "191/191 [==============================] - 0s 79us/step - loss: 1.9710 - acc: 0.6126 - val_loss: 0.5296 - val_acc: 0.7059\n",
      "Epoch 45/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.6378 - acc: 0.6440 - val_loss: 0.5223 - val_acc: 0.7059\n",
      "Epoch 46/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 1.4620 - acc: 0.6440 - val_loss: 0.5326 - val_acc: 0.7941\n",
      "Epoch 47/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 1.6963 - acc: 0.6021 - val_loss: 0.5800 - val_acc: 0.8235\n",
      "Epoch 48/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.8408 - acc: 0.5759 - val_loss: 0.5360 - val_acc: 0.7941\n",
      "Epoch 49/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.6004 - acc: 0.6335 - val_loss: 0.5262 - val_acc: 0.7059\n",
      "Epoch 50/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 1.9920 - acc: 0.5602 - val_loss: 0.5269 - val_acc: 0.7059\n",
      "Epoch 51/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.6044 - acc: 0.6178 - val_loss: 0.5279 - val_acc: 0.7059\n",
      "Epoch 52/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.5778 - acc: 0.6649 - val_loss: 0.5276 - val_acc: 0.7353\n",
      "Epoch 53/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.4005 - acc: 0.6021 - val_loss: 0.5182 - val_acc: 0.7353\n",
      "Epoch 54/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.3015 - acc: 0.6597 - val_loss: 0.5160 - val_acc: 0.7647\n",
      "Epoch 55/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 1.8959 - acc: 0.5550 - val_loss: 0.5342 - val_acc: 0.8235\n",
      "Epoch 56/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.4983 - acc: 0.6283 - val_loss: 0.5229 - val_acc: 0.8235\n",
      "Epoch 57/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.4242 - acc: 0.6597 - val_loss: 0.5655 - val_acc: 0.7647\n",
      "Epoch 58/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 1.4043 - acc: 0.6754 - val_loss: 0.6043 - val_acc: 0.7647\n",
      "Epoch 59/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.4262 - acc: 0.6702 - val_loss: 0.5853 - val_acc: 0.7647\n",
      "Epoch 60/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.8475 - acc: 0.6230 - val_loss: 0.4928 - val_acc: 0.7647\n",
      "Epoch 61/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.3437 - acc: 0.6178 - val_loss: 0.5681 - val_acc: 0.6765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.7996 - acc: 0.6126 - val_loss: 0.5408 - val_acc: 0.6765\n",
      "Epoch 63/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.3394 - acc: 0.6545 - val_loss: 0.4930 - val_acc: 0.7353\n",
      "Epoch 64/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.4164 - acc: 0.6492 - val_loss: 0.5135 - val_acc: 0.8235\n",
      "Epoch 65/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.3001 - acc: 0.6597 - val_loss: 0.4859 - val_acc: 0.7353\n",
      "Epoch 66/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.5506 - acc: 0.6126 - val_loss: 0.4833 - val_acc: 0.7353\n",
      "Epoch 67/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 1.3885 - acc: 0.6387 - val_loss: 0.4533 - val_acc: 0.7647\n",
      "Epoch 68/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.4309 - acc: 0.6178 - val_loss: 0.4566 - val_acc: 0.7647\n",
      "Epoch 69/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.1808 - acc: 0.6545 - val_loss: 0.4647 - val_acc: 0.7647\n",
      "Epoch 70/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.6940 - acc: 0.5340 - val_loss: 0.4742 - val_acc: 0.8235\n",
      "Epoch 71/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.1706 - acc: 0.6702 - val_loss: 0.4931 - val_acc: 0.8235\n",
      "Epoch 72/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.0399 - acc: 0.7173 - val_loss: 0.4795 - val_acc: 0.7059\n",
      "Epoch 73/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.1867 - acc: 0.6545 - val_loss: 0.5487 - val_acc: 0.6765\n",
      "Epoch 74/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.2377 - acc: 0.6073 - val_loss: 0.5086 - val_acc: 0.7647\n",
      "Epoch 75/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.3437 - acc: 0.6178 - val_loss: 0.5010 - val_acc: 0.7941\n",
      "Epoch 76/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 1.2569 - acc: 0.6702 - val_loss: 0.4619 - val_acc: 0.8529\n",
      "Epoch 77/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.2610 - acc: 0.6335 - val_loss: 0.4269 - val_acc: 0.7941\n",
      "Epoch 78/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.2031 - acc: 0.6859 - val_loss: 0.4584 - val_acc: 0.7353\n",
      "Epoch 79/500\n",
      "191/191 [==============================] - 0s 74us/step - loss: 1.3301 - acc: 0.6126 - val_loss: 0.4515 - val_acc: 0.7059\n",
      "Epoch 80/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.0270 - acc: 0.7016 - val_loss: 0.4026 - val_acc: 0.7353\n",
      "Epoch 81/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 1.3173 - acc: 0.5759 - val_loss: 0.4053 - val_acc: 0.8235\n",
      "Epoch 82/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.3242 - acc: 0.5812 - val_loss: 0.4008 - val_acc: 0.7941\n",
      "Epoch 83/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 1.1029 - acc: 0.6806 - val_loss: 0.4212 - val_acc: 0.7059\n",
      "Epoch 84/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.4941 - acc: 0.5969 - val_loss: 0.4125 - val_acc: 0.7059\n",
      "Epoch 85/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 1.1556 - acc: 0.6492 - val_loss: 0.3954 - val_acc: 0.8235\n",
      "Epoch 86/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.9847 - acc: 0.6754 - val_loss: 0.4487 - val_acc: 0.8235\n",
      "Epoch 87/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.8395 - acc: 0.7330 - val_loss: 0.4195 - val_acc: 0.8235\n",
      "Epoch 88/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.1357 - acc: 0.6702 - val_loss: 0.4244 - val_acc: 0.7647\n",
      "Epoch 89/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.9137 - acc: 0.6911 - val_loss: 0.4803 - val_acc: 0.6765\n",
      "Epoch 90/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 1.0985 - acc: 0.6283 - val_loss: 0.3674 - val_acc: 0.7941\n",
      "Epoch 91/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.2216 - acc: 0.6440 - val_loss: 0.3804 - val_acc: 0.8235\n",
      "Epoch 92/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 1.0697 - acc: 0.6545 - val_loss: 0.4108 - val_acc: 0.7647\n",
      "Epoch 93/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 1.1358 - acc: 0.5969 - val_loss: 0.3991 - val_acc: 0.7941\n",
      "Epoch 94/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 1.0757 - acc: 0.6597 - val_loss: 0.4063 - val_acc: 0.7647\n",
      "Epoch 95/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.8949 - acc: 0.7016 - val_loss: 0.4073 - val_acc: 0.7941\n",
      "Epoch 96/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.9458 - acc: 0.6806 - val_loss: 0.4164 - val_acc: 0.8235\n",
      "Epoch 97/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.9213 - acc: 0.6649 - val_loss: 0.4328 - val_acc: 0.7647\n",
      "Epoch 98/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.1006 - acc: 0.6021 - val_loss: 0.4550 - val_acc: 0.7353\n",
      "Epoch 99/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.8896 - acc: 0.6754 - val_loss: 0.5470 - val_acc: 0.6765\n",
      "Epoch 100/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.9279 - acc: 0.6073 - val_loss: 0.4614 - val_acc: 0.7059\n",
      "Epoch 101/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.9983 - acc: 0.6806 - val_loss: 0.4220 - val_acc: 0.7647\n",
      "Epoch 102/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 1.0564 - acc: 0.6492 - val_loss: 0.4163 - val_acc: 0.7647\n",
      "Epoch 103/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.8144 - acc: 0.7173 - val_loss: 0.4823 - val_acc: 0.6765\n",
      "Epoch 104/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.8693 - acc: 0.7120 - val_loss: 0.5609 - val_acc: 0.6765\n",
      "Epoch 105/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.9684 - acc: 0.6649 - val_loss: 0.3851 - val_acc: 0.7941\n",
      "Epoch 106/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.8634 - acc: 0.6597 - val_loss: 0.3889 - val_acc: 0.8235\n",
      "Epoch 107/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 1.1891 - acc: 0.6073 - val_loss: 0.3963 - val_acc: 0.7647\n",
      "Epoch 108/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 1.0380 - acc: 0.6178 - val_loss: 0.4647 - val_acc: 0.7059\n",
      "Epoch 109/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.9520 - acc: 0.6649 - val_loss: 0.4351 - val_acc: 0.7059\n",
      "Epoch 110/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.8330 - acc: 0.6387 - val_loss: 0.3708 - val_acc: 0.7647\n",
      "Epoch 111/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.8668 - acc: 0.6963 - val_loss: 0.3589 - val_acc: 0.8235\n",
      "Epoch 112/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.9845 - acc: 0.6911 - val_loss: 0.3491 - val_acc: 0.8529\n",
      "Epoch 113/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.8002 - acc: 0.6806 - val_loss: 0.4710 - val_acc: 0.7059\n",
      "Epoch 114/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.6293 - acc: 0.7592 - val_loss: 0.4564 - val_acc: 0.7059\n",
      "Epoch 115/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.7593 - acc: 0.7173 - val_loss: 0.3478 - val_acc: 0.7941\n",
      "Epoch 116/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.7473 - acc: 0.7330 - val_loss: 0.3361 - val_acc: 0.8529\n",
      "Epoch 117/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.8499 - acc: 0.7068 - val_loss: 0.3509 - val_acc: 0.7647\n",
      "Epoch 118/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.7928 - acc: 0.7330 - val_loss: 0.6549 - val_acc: 0.6176\n",
      "Epoch 119/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.8331 - acc: 0.6597 - val_loss: 0.5042 - val_acc: 0.7059\n",
      "Epoch 120/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.7366 - acc: 0.6911 - val_loss: 0.3239 - val_acc: 0.9118\n",
      "Epoch 121/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.7471 - acc: 0.7016 - val_loss: 0.3265 - val_acc: 0.8824\n",
      "Epoch 122/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.7759 - acc: 0.7016 - val_loss: 0.4758 - val_acc: 0.7059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.7704 - acc: 0.6754 - val_loss: 0.5250 - val_acc: 0.6765\n",
      "Epoch 124/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.8447 - acc: 0.6440 - val_loss: 0.3494 - val_acc: 0.8529\n",
      "Epoch 125/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.8795 - acc: 0.6754 - val_loss: 0.3599 - val_acc: 0.8529\n",
      "Epoch 126/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.8485 - acc: 0.6440 - val_loss: 0.6222 - val_acc: 0.6471\n",
      "Epoch 127/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.7470 - acc: 0.6702 - val_loss: 0.8158 - val_acc: 0.6176\n",
      "Epoch 128/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.7888 - acc: 0.6440 - val_loss: 0.3640 - val_acc: 0.8529\n",
      "Epoch 129/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.7273 - acc: 0.6859 - val_loss: 0.3642 - val_acc: 0.8529\n",
      "Epoch 130/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.8400 - acc: 0.6859 - val_loss: 0.4788 - val_acc: 0.6765\n",
      "Epoch 131/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.6539 - acc: 0.7539 - val_loss: 0.5297 - val_acc: 0.6765\n",
      "Epoch 132/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.7050 - acc: 0.7277 - val_loss: 0.3701 - val_acc: 0.8235\n",
      "Epoch 133/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.6710 - acc: 0.7016 - val_loss: 0.3368 - val_acc: 0.8529\n",
      "Epoch 134/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.7201 - acc: 0.7120 - val_loss: 0.3296 - val_acc: 0.8824\n",
      "Epoch 135/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.6078 - acc: 0.7435 - val_loss: 0.4289 - val_acc: 0.7059\n",
      "Epoch 136/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.7717 - acc: 0.6859 - val_loss: 0.4524 - val_acc: 0.7059\n",
      "Epoch 137/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.6454 - acc: 0.7644 - val_loss: 0.3256 - val_acc: 0.8824\n",
      "Epoch 138/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.7409 - acc: 0.6963 - val_loss: 0.3537 - val_acc: 0.8529\n",
      "Epoch 139/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.5755 - acc: 0.7487 - val_loss: 0.3482 - val_acc: 0.8529\n",
      "Epoch 140/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.5923 - acc: 0.7853 - val_loss: 0.6246 - val_acc: 0.6471\n",
      "Epoch 141/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.6914 - acc: 0.6963 - val_loss: 0.5071 - val_acc: 0.6765\n",
      "Epoch 142/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.7024 - acc: 0.6806 - val_loss: 0.3560 - val_acc: 0.8529\n",
      "Epoch 143/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.7021 - acc: 0.7592 - val_loss: 0.3535 - val_acc: 0.8529\n",
      "Epoch 144/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.6760 - acc: 0.7330 - val_loss: 0.4539 - val_acc: 0.7059\n",
      "Epoch 145/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.6734 - acc: 0.7382 - val_loss: 0.4963 - val_acc: 0.7059\n",
      "Epoch 146/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.7439 - acc: 0.6492 - val_loss: 0.3508 - val_acc: 0.8235\n",
      "Epoch 147/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.5230 - acc: 0.7225 - val_loss: 0.3365 - val_acc: 0.8529\n",
      "Epoch 148/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.6064 - acc: 0.7225 - val_loss: 0.3559 - val_acc: 0.8235\n",
      "Epoch 149/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.6052 - acc: 0.7382 - val_loss: 0.4730 - val_acc: 0.7059\n",
      "Epoch 150/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.6221 - acc: 0.7382 - val_loss: 0.3616 - val_acc: 0.8529\n",
      "Epoch 151/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.5881 - acc: 0.7696 - val_loss: 0.3461 - val_acc: 0.8235\n",
      "Epoch 152/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.6333 - acc: 0.7487 - val_loss: 0.4020 - val_acc: 0.7941\n",
      "Epoch 153/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.6988 - acc: 0.7173 - val_loss: 0.5212 - val_acc: 0.6765\n",
      "Epoch 154/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.6303 - acc: 0.7330 - val_loss: 0.3339 - val_acc: 0.8529\n",
      "Epoch 155/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.6668 - acc: 0.7173 - val_loss: 0.3361 - val_acc: 0.8529\n",
      "Epoch 156/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.6472 - acc: 0.7173 - val_loss: 0.3666 - val_acc: 0.8235\n",
      "Epoch 157/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.5855 - acc: 0.7487 - val_loss: 0.4392 - val_acc: 0.7059\n",
      "Epoch 158/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.6393 - acc: 0.7225 - val_loss: 0.3266 - val_acc: 0.8529\n",
      "Epoch 159/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5996 - acc: 0.7487 - val_loss: 0.3176 - val_acc: 0.8529\n",
      "Epoch 160/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.5605 - acc: 0.7749 - val_loss: 0.4417 - val_acc: 0.7059\n",
      "Epoch 161/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.6481 - acc: 0.6754 - val_loss: 0.3718 - val_acc: 0.7941\n",
      "Epoch 162/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.5842 - acc: 0.7539 - val_loss: 0.3208 - val_acc: 0.8529\n",
      "Epoch 163/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5633 - acc: 0.7435 - val_loss: 0.3224 - val_acc: 0.8529\n",
      "Epoch 164/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5192 - acc: 0.7801 - val_loss: 0.4425 - val_acc: 0.7059\n",
      "Epoch 165/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.6072 - acc: 0.7330 - val_loss: 0.4091 - val_acc: 0.7059\n",
      "Epoch 166/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.6085 - acc: 0.7016 - val_loss: 0.3337 - val_acc: 0.8529\n",
      "Epoch 167/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.6690 - acc: 0.7435 - val_loss: 0.3212 - val_acc: 0.8529\n",
      "Epoch 168/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.5550 - acc: 0.7644 - val_loss: 0.4086 - val_acc: 0.7059\n",
      "Epoch 169/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.6415 - acc: 0.7435 - val_loss: 0.3673 - val_acc: 0.8235\n",
      "Epoch 170/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4822 - acc: 0.7801 - val_loss: 0.3230 - val_acc: 0.8529\n",
      "Epoch 171/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.6243 - acc: 0.7644 - val_loss: 0.3283 - val_acc: 0.8529\n",
      "Epoch 172/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5946 - acc: 0.7801 - val_loss: 0.3980 - val_acc: 0.7647\n",
      "Epoch 173/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.6568 - acc: 0.7277 - val_loss: 0.3544 - val_acc: 0.7941\n",
      "Epoch 174/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5898 - acc: 0.7382 - val_loss: 0.3227 - val_acc: 0.8529\n",
      "Epoch 175/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.5792 - acc: 0.7173 - val_loss: 0.3298 - val_acc: 0.8824\n",
      "Epoch 176/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.5090 - acc: 0.7749 - val_loss: 0.3938 - val_acc: 0.7353\n",
      "Epoch 177/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.5307 - acc: 0.7696 - val_loss: 0.3350 - val_acc: 0.8824\n",
      "Epoch 178/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5731 - acc: 0.7592 - val_loss: 0.3051 - val_acc: 0.8529\n",
      "Epoch 179/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.5816 - acc: 0.7435 - val_loss: 0.3454 - val_acc: 0.8529\n",
      "Epoch 180/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5077 - acc: 0.7696 - val_loss: 0.3384 - val_acc: 0.8529\n",
      "Epoch 181/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5391 - acc: 0.7539 - val_loss: 0.3165 - val_acc: 0.8824\n",
      "Epoch 182/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.5608 - acc: 0.7592 - val_loss: 0.3376 - val_acc: 0.8529\n",
      "Epoch 183/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.5442 - acc: 0.7382 - val_loss: 0.3643 - val_acc: 0.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5164 - acc: 0.7749 - val_loss: 0.3200 - val_acc: 0.8824\n",
      "Epoch 185/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4821 - acc: 0.7696 - val_loss: 0.3151 - val_acc: 0.8529\n",
      "Epoch 186/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4213 - acc: 0.8168 - val_loss: 0.3376 - val_acc: 0.9118\n",
      "Epoch 187/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5229 - acc: 0.7277 - val_loss: 0.3522 - val_acc: 0.8529\n",
      "Epoch 188/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4768 - acc: 0.7906 - val_loss: 0.3410 - val_acc: 0.8824\n",
      "Epoch 189/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4703 - acc: 0.7853 - val_loss: 0.3103 - val_acc: 0.8529\n",
      "Epoch 190/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4993 - acc: 0.7696 - val_loss: 0.3128 - val_acc: 0.8824\n",
      "Epoch 191/500\n",
      "191/191 [==============================] - 0s 74us/step - loss: 0.4894 - acc: 0.8010 - val_loss: 0.3399 - val_acc: 0.8824\n",
      "Epoch 192/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.5219 - acc: 0.7592 - val_loss: 0.3018 - val_acc: 0.8529\n",
      "Epoch 193/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5046 - acc: 0.7696 - val_loss: 0.3004 - val_acc: 0.8529\n",
      "Epoch 194/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.5620 - acc: 0.7539 - val_loss: 0.3426 - val_acc: 0.8529\n",
      "Epoch 195/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4380 - acc: 0.8063 - val_loss: 0.4126 - val_acc: 0.7941\n",
      "Epoch 196/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4969 - acc: 0.7644 - val_loss: 0.3215 - val_acc: 0.8529\n",
      "Epoch 197/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.4994 - acc: 0.7696 - val_loss: 0.3397 - val_acc: 0.8529\n",
      "Epoch 198/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.5989 - acc: 0.7801 - val_loss: 0.3637 - val_acc: 0.7941\n",
      "Epoch 199/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.4432 - acc: 0.7958 - val_loss: 0.4608 - val_acc: 0.7353\n",
      "Epoch 200/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5649 - acc: 0.7068 - val_loss: 0.3377 - val_acc: 0.8529\n",
      "Epoch 201/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4974 - acc: 0.7644 - val_loss: 0.3389 - val_acc: 0.8529\n",
      "Epoch 202/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4351 - acc: 0.7906 - val_loss: 0.3723 - val_acc: 0.7941\n",
      "Epoch 203/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.4510 - acc: 0.7801 - val_loss: 0.4352 - val_acc: 0.7647\n",
      "Epoch 204/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5089 - acc: 0.7696 - val_loss: 0.3139 - val_acc: 0.8529\n",
      "Epoch 205/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.4468 - acc: 0.8010 - val_loss: 0.3383 - val_acc: 0.8824\n",
      "Epoch 206/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.4377 - acc: 0.8010 - val_loss: 0.3214 - val_acc: 0.8824\n",
      "Epoch 207/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.4299 - acc: 0.7906 - val_loss: 0.3965 - val_acc: 0.7353\n",
      "Epoch 208/500\n",
      "191/191 [==============================] - 0s 79us/step - loss: 0.5693 - acc: 0.7330 - val_loss: 0.3054 - val_acc: 0.8529\n",
      "Epoch 209/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4794 - acc: 0.7853 - val_loss: 0.3230 - val_acc: 0.8824\n",
      "Epoch 210/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4988 - acc: 0.7906 - val_loss: 0.3123 - val_acc: 0.8824\n",
      "Epoch 211/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4587 - acc: 0.7749 - val_loss: 0.3955 - val_acc: 0.7647\n",
      "Epoch 212/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.5836 - acc: 0.7068 - val_loss: 0.3061 - val_acc: 0.8824\n",
      "Epoch 213/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5375 - acc: 0.7801 - val_loss: 0.3362 - val_acc: 0.8529\n",
      "Epoch 214/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5294 - acc: 0.7801 - val_loss: 0.3074 - val_acc: 0.8824\n",
      "Epoch 215/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.4777 - acc: 0.7853 - val_loss: 0.4546 - val_acc: 0.7059\n",
      "Epoch 216/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4980 - acc: 0.7277 - val_loss: 0.3098 - val_acc: 0.8824\n",
      "Epoch 217/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4222 - acc: 0.7958 - val_loss: 0.3490 - val_acc: 0.8529\n",
      "Epoch 218/500\n",
      "191/191 [==============================] - 0s 89us/step - loss: 0.5648 - acc: 0.7644 - val_loss: 0.3028 - val_acc: 0.8824\n",
      "Epoch 219/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4285 - acc: 0.8168 - val_loss: 0.5235 - val_acc: 0.6176\n",
      "Epoch 220/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.6029 - acc: 0.6806 - val_loss: 0.3036 - val_acc: 0.8529\n",
      "Epoch 221/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4580 - acc: 0.8168 - val_loss: 0.3737 - val_acc: 0.8824\n",
      "Epoch 222/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5204 - acc: 0.7906 - val_loss: 0.3130 - val_acc: 0.8529\n",
      "Epoch 223/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.4069 - acc: 0.8063 - val_loss: 0.5588 - val_acc: 0.6176\n",
      "Epoch 224/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.5802 - acc: 0.6963 - val_loss: 0.3114 - val_acc: 0.8529\n",
      "Epoch 225/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4969 - acc: 0.7435 - val_loss: 0.4329 - val_acc: 0.8235\n",
      "Epoch 226/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.5885 - acc: 0.7173 - val_loss: 0.3281 - val_acc: 0.8529\n",
      "Epoch 227/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4261 - acc: 0.7853 - val_loss: 0.4988 - val_acc: 0.6765\n",
      "Epoch 228/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.5485 - acc: 0.7539 - val_loss: 0.3200 - val_acc: 0.8824\n",
      "Epoch 229/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3846 - acc: 0.8325 - val_loss: 0.3568 - val_acc: 0.8529\n",
      "Epoch 230/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4842 - acc: 0.7801 - val_loss: 0.3282 - val_acc: 0.8529\n",
      "Epoch 231/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4412 - acc: 0.7801 - val_loss: 0.4201 - val_acc: 0.7353\n",
      "Epoch 232/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4979 - acc: 0.7487 - val_loss: 0.3324 - val_acc: 0.8529\n",
      "Epoch 233/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.4352 - acc: 0.8063 - val_loss: 0.3254 - val_acc: 0.8529\n",
      "Epoch 234/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4039 - acc: 0.8325 - val_loss: 0.3166 - val_acc: 0.8529\n",
      "Epoch 235/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4728 - acc: 0.8010 - val_loss: 0.3743 - val_acc: 0.7941\n",
      "Epoch 236/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3980 - acc: 0.8115 - val_loss: 0.3168 - val_acc: 0.8529\n",
      "Epoch 237/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4504 - acc: 0.8272 - val_loss: 0.3289 - val_acc: 0.8529\n",
      "Epoch 238/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4145 - acc: 0.8115 - val_loss: 0.3203 - val_acc: 0.8824\n",
      "Epoch 239/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4329 - acc: 0.8010 - val_loss: 0.3741 - val_acc: 0.7941\n",
      "Epoch 240/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4246 - acc: 0.7801 - val_loss: 0.3266 - val_acc: 0.8824\n",
      "Epoch 241/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3978 - acc: 0.8429 - val_loss: 0.3424 - val_acc: 0.8824\n",
      "Epoch 242/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4441 - acc: 0.8168 - val_loss: 0.3192 - val_acc: 0.8529\n",
      "Epoch 243/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.4049 - acc: 0.8325 - val_loss: 0.3799 - val_acc: 0.8235\n",
      "Epoch 244/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4663 - acc: 0.7801 - val_loss: 0.3194 - val_acc: 0.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.4299 - acc: 0.7853 - val_loss: 0.3238 - val_acc: 0.8529\n",
      "Epoch 246/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.4464 - acc: 0.7958 - val_loss: 0.3105 - val_acc: 0.8529\n",
      "Epoch 247/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4265 - acc: 0.8010 - val_loss: 0.3479 - val_acc: 0.8529\n",
      "Epoch 248/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4378 - acc: 0.7853 - val_loss: 0.3093 - val_acc: 0.8824\n",
      "Epoch 249/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.3456 - acc: 0.8639 - val_loss: 0.3158 - val_acc: 0.8529\n",
      "Epoch 250/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4004 - acc: 0.8377 - val_loss: 0.3103 - val_acc: 0.8824\n",
      "Epoch 251/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4671 - acc: 0.7644 - val_loss: 0.3230 - val_acc: 0.8824\n",
      "Epoch 252/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4006 - acc: 0.8534 - val_loss: 0.3195 - val_acc: 0.8824\n",
      "Epoch 253/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3813 - acc: 0.8168 - val_loss: 0.3118 - val_acc: 0.8529\n",
      "Epoch 254/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.4411 - acc: 0.8010 - val_loss: 0.3126 - val_acc: 0.8824\n",
      "Epoch 255/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4104 - acc: 0.7906 - val_loss: 0.3144 - val_acc: 0.8529\n",
      "Epoch 256/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.4023 - acc: 0.8168 - val_loss: 0.3170 - val_acc: 0.8529\n",
      "Epoch 257/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.4137 - acc: 0.8168 - val_loss: 0.3246 - val_acc: 0.8824\n",
      "Epoch 258/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.4247 - acc: 0.8115 - val_loss: 0.3397 - val_acc: 0.8235\n",
      "Epoch 259/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4020 - acc: 0.8325 - val_loss: 0.3221 - val_acc: 0.8529\n",
      "Epoch 260/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3982 - acc: 0.8168 - val_loss: 0.3357 - val_acc: 0.8529\n",
      "Epoch 261/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4362 - acc: 0.7853 - val_loss: 0.3252 - val_acc: 0.8529\n",
      "Epoch 262/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.3592 - acc: 0.8639 - val_loss: 0.3333 - val_acc: 0.8529\n",
      "Epoch 263/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.4180 - acc: 0.8168 - val_loss: 0.3302 - val_acc: 0.8529\n",
      "Epoch 264/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4272 - acc: 0.8115 - val_loss: 0.3242 - val_acc: 0.8529\n",
      "Epoch 265/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3542 - acc: 0.8377 - val_loss: 0.3425 - val_acc: 0.8824\n",
      "Epoch 266/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.4250 - acc: 0.8063 - val_loss: 0.3271 - val_acc: 0.8824\n",
      "Epoch 267/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3749 - acc: 0.8272 - val_loss: 0.3261 - val_acc: 0.8529\n",
      "Epoch 268/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3529 - acc: 0.8272 - val_loss: 0.3219 - val_acc: 0.8529\n",
      "Epoch 269/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3611 - acc: 0.8429 - val_loss: 0.3280 - val_acc: 0.8824\n",
      "Epoch 270/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3742 - acc: 0.8482 - val_loss: 0.3381 - val_acc: 0.8824\n",
      "Epoch 271/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3907 - acc: 0.8220 - val_loss: 0.3248 - val_acc: 0.8529\n",
      "Epoch 272/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3730 - acc: 0.8220 - val_loss: 0.3217 - val_acc: 0.8529\n",
      "Epoch 273/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3623 - acc: 0.8482 - val_loss: 0.3416 - val_acc: 0.8235\n",
      "Epoch 274/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.4115 - acc: 0.8115 - val_loss: 0.3561 - val_acc: 0.8529\n",
      "Epoch 275/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.4036 - acc: 0.8063 - val_loss: 0.3433 - val_acc: 0.8529\n",
      "Epoch 276/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4541 - acc: 0.7906 - val_loss: 0.3406 - val_acc: 0.8529\n",
      "Epoch 277/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3837 - acc: 0.8220 - val_loss: 0.3686 - val_acc: 0.7647\n",
      "Epoch 278/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.4267 - acc: 0.8063 - val_loss: 0.3419 - val_acc: 0.8235\n",
      "Epoch 279/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4026 - acc: 0.8325 - val_loss: 0.3614 - val_acc: 0.8824\n",
      "Epoch 280/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4248 - acc: 0.8010 - val_loss: 0.3219 - val_acc: 0.8529\n",
      "Epoch 281/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.4099 - acc: 0.8220 - val_loss: 0.3474 - val_acc: 0.8824\n",
      "Epoch 282/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3815 - acc: 0.8325 - val_loss: 0.3306 - val_acc: 0.8824\n",
      "Epoch 283/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.4008 - acc: 0.7906 - val_loss: 0.3440 - val_acc: 0.8529\n",
      "Epoch 284/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.4105 - acc: 0.8220 - val_loss: 0.3202 - val_acc: 0.8824\n",
      "Epoch 285/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3448 - acc: 0.8272 - val_loss: 0.3533 - val_acc: 0.8529\n",
      "Epoch 286/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3657 - acc: 0.8377 - val_loss: 0.3249 - val_acc: 0.8824\n",
      "Epoch 287/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.3848 - acc: 0.8168 - val_loss: 0.3533 - val_acc: 0.8824\n",
      "Epoch 288/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.4097 - acc: 0.8377 - val_loss: 0.3385 - val_acc: 0.8824\n",
      "Epoch 289/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3941 - acc: 0.8168 - val_loss: 0.3774 - val_acc: 0.7941\n",
      "Epoch 290/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.3595 - acc: 0.8586 - val_loss: 0.3350 - val_acc: 0.8824\n",
      "Epoch 291/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3525 - acc: 0.8429 - val_loss: 0.3368 - val_acc: 0.8529\n",
      "Epoch 292/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.3561 - acc: 0.8272 - val_loss: 0.3247 - val_acc: 0.8824\n",
      "Epoch 293/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3167 - acc: 0.8482 - val_loss: 0.3271 - val_acc: 0.8824\n",
      "Epoch 294/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3977 - acc: 0.8063 - val_loss: 0.3189 - val_acc: 0.8529\n",
      "Epoch 295/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.3648 - acc: 0.8220 - val_loss: 0.3248 - val_acc: 0.8529\n",
      "Epoch 296/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3790 - acc: 0.8482 - val_loss: 0.3218 - val_acc: 0.8529\n",
      "Epoch 297/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3437 - acc: 0.8691 - val_loss: 0.3267 - val_acc: 0.8529\n",
      "Epoch 298/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3966 - acc: 0.8115 - val_loss: 0.3302 - val_acc: 0.8529\n",
      "Epoch 299/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3676 - acc: 0.8377 - val_loss: 0.3316 - val_acc: 0.8529\n",
      "Epoch 300/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3614 - acc: 0.8377 - val_loss: 0.3360 - val_acc: 0.8529\n",
      "Epoch 301/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3432 - acc: 0.8272 - val_loss: 0.3372 - val_acc: 0.8824\n",
      "Epoch 302/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3441 - acc: 0.8691 - val_loss: 0.3382 - val_acc: 0.8824\n",
      "Epoch 303/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3976 - acc: 0.8115 - val_loss: 0.3334 - val_acc: 0.8529\n",
      "Epoch 304/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3637 - acc: 0.8429 - val_loss: 0.3251 - val_acc: 0.8824\n",
      "Epoch 305/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3320 - acc: 0.8534 - val_loss: 0.3330 - val_acc: 0.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3209 - acc: 0.8429 - val_loss: 0.3182 - val_acc: 0.8824\n",
      "Epoch 307/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3590 - acc: 0.8325 - val_loss: 0.3159 - val_acc: 0.8529\n",
      "Epoch 308/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3514 - acc: 0.8272 - val_loss: 0.3264 - val_acc: 0.8529\n",
      "Epoch 309/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3516 - acc: 0.8272 - val_loss: 0.3328 - val_acc: 0.8824\n",
      "Epoch 310/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3504 - acc: 0.8429 - val_loss: 0.3288 - val_acc: 0.8824\n",
      "Epoch 311/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3561 - acc: 0.8272 - val_loss: 0.3360 - val_acc: 0.8529\n",
      "Epoch 312/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3764 - acc: 0.7958 - val_loss: 0.3428 - val_acc: 0.8529\n",
      "Epoch 313/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3658 - acc: 0.8325 - val_loss: 0.3378 - val_acc: 0.8824\n",
      "Epoch 314/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3872 - acc: 0.8220 - val_loss: 0.3413 - val_acc: 0.8529\n",
      "Epoch 315/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3289 - acc: 0.8743 - val_loss: 0.3282 - val_acc: 0.8824\n",
      "Epoch 316/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3340 - acc: 0.8743 - val_loss: 0.3280 - val_acc: 0.8529\n",
      "Epoch 317/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3557 - acc: 0.8220 - val_loss: 0.3204 - val_acc: 0.8529\n",
      "Epoch 318/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3446 - acc: 0.8429 - val_loss: 0.3373 - val_acc: 0.8824\n",
      "Epoch 319/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3728 - acc: 0.8325 - val_loss: 0.3235 - val_acc: 0.8529\n",
      "Epoch 320/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3323 - acc: 0.8429 - val_loss: 0.3294 - val_acc: 0.8529\n",
      "Epoch 321/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3467 - acc: 0.8586 - val_loss: 0.3538 - val_acc: 0.8529\n",
      "Epoch 322/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.3469 - acc: 0.8482 - val_loss: 0.3376 - val_acc: 0.8824\n",
      "Epoch 323/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3264 - acc: 0.8325 - val_loss: 0.3432 - val_acc: 0.8529\n",
      "Epoch 324/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3571 - acc: 0.8639 - val_loss: 0.3328 - val_acc: 0.8529\n",
      "Epoch 325/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3530 - acc: 0.8220 - val_loss: 0.3483 - val_acc: 0.8824\n",
      "Epoch 326/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3580 - acc: 0.8325 - val_loss: 0.3181 - val_acc: 0.8824\n",
      "Epoch 327/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3733 - acc: 0.8325 - val_loss: 0.3249 - val_acc: 0.8529\n",
      "Epoch 328/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3449 - acc: 0.8743 - val_loss: 0.3100 - val_acc: 0.8529\n",
      "Epoch 329/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3249 - acc: 0.8586 - val_loss: 0.3167 - val_acc: 0.8824\n",
      "Epoch 330/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3547 - acc: 0.8377 - val_loss: 0.3188 - val_acc: 0.8529\n",
      "Epoch 331/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3608 - acc: 0.8272 - val_loss: 0.3265 - val_acc: 0.8529\n",
      "Epoch 332/500\n",
      "191/191 [==============================] - 0s 79us/step - loss: 0.3274 - acc: 0.8325 - val_loss: 0.3272 - val_acc: 0.8824\n",
      "Epoch 333/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3652 - acc: 0.8272 - val_loss: 0.3384 - val_acc: 0.8529\n",
      "Epoch 334/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3565 - acc: 0.8377 - val_loss: 0.3263 - val_acc: 0.8529\n",
      "Epoch 335/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3355 - acc: 0.8377 - val_loss: 0.3250 - val_acc: 0.8824\n",
      "Epoch 336/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3243 - acc: 0.8325 - val_loss: 0.3230 - val_acc: 0.8824\n",
      "Epoch 337/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3397 - acc: 0.8429 - val_loss: 0.3216 - val_acc: 0.8824\n",
      "Epoch 338/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3415 - acc: 0.8429 - val_loss: 0.3219 - val_acc: 0.8824\n",
      "Epoch 339/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3650 - acc: 0.8377 - val_loss: 0.3220 - val_acc: 0.8529\n",
      "Epoch 340/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3175 - acc: 0.8691 - val_loss: 0.3349 - val_acc: 0.8529\n",
      "Epoch 341/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2861 - acc: 0.8691 - val_loss: 0.3298 - val_acc: 0.8529\n",
      "Epoch 342/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3649 - acc: 0.8429 - val_loss: 0.3526 - val_acc: 0.8529\n",
      "Epoch 343/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3763 - acc: 0.8168 - val_loss: 0.3372 - val_acc: 0.8529\n",
      "Epoch 344/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3302 - acc: 0.8482 - val_loss: 0.3497 - val_acc: 0.8529\n",
      "Epoch 345/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3373 - acc: 0.8639 - val_loss: 0.3460 - val_acc: 0.8824\n",
      "Epoch 346/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2978 - acc: 0.8691 - val_loss: 0.3734 - val_acc: 0.8529\n",
      "Epoch 347/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3306 - acc: 0.8534 - val_loss: 0.3542 - val_acc: 0.8824\n",
      "Epoch 348/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3261 - acc: 0.8482 - val_loss: 0.3551 - val_acc: 0.8529\n",
      "Epoch 349/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3676 - acc: 0.8639 - val_loss: 0.3462 - val_acc: 0.8824\n",
      "Epoch 350/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3036 - acc: 0.8848 - val_loss: 0.3438 - val_acc: 0.8824\n",
      "Epoch 351/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3558 - acc: 0.8482 - val_loss: 0.3403 - val_acc: 0.8529\n",
      "Epoch 352/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.3175 - acc: 0.8429 - val_loss: 0.3413 - val_acc: 0.8529\n",
      "Epoch 353/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3426 - acc: 0.8691 - val_loss: 0.4006 - val_acc: 0.7353\n",
      "Epoch 354/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4192 - acc: 0.8272 - val_loss: 0.3367 - val_acc: 0.8529\n",
      "Epoch 355/500\n",
      "191/191 [==============================] - 0s 74us/step - loss: 0.3324 - acc: 0.8691 - val_loss: 0.4073 - val_acc: 0.8529\n",
      "Epoch 356/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3858 - acc: 0.8325 - val_loss: 0.3468 - val_acc: 0.8529\n",
      "Epoch 357/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3392 - acc: 0.8482 - val_loss: 0.4185 - val_acc: 0.7353\n",
      "Epoch 358/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.4056 - acc: 0.7906 - val_loss: 0.3414 - val_acc: 0.8235\n",
      "Epoch 359/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3507 - acc: 0.8429 - val_loss: 0.3848 - val_acc: 0.8529\n",
      "Epoch 360/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3691 - acc: 0.8272 - val_loss: 0.3272 - val_acc: 0.8529\n",
      "Epoch 361/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3237 - acc: 0.8482 - val_loss: 0.4072 - val_acc: 0.7059\n",
      "Epoch 362/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.4038 - acc: 0.8115 - val_loss: 0.3252 - val_acc: 0.8529\n",
      "Epoch 363/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3498 - acc: 0.8429 - val_loss: 0.3502 - val_acc: 0.8529\n",
      "Epoch 364/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3717 - acc: 0.8325 - val_loss: 0.3379 - val_acc: 0.8824\n",
      "Epoch 365/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3260 - acc: 0.8691 - val_loss: 0.3851 - val_acc: 0.7353\n",
      "Epoch 366/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3533 - acc: 0.8272 - val_loss: 0.3603 - val_acc: 0.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3363 - acc: 0.8691 - val_loss: 0.3869 - val_acc: 0.8529\n",
      "Epoch 368/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3416 - acc: 0.8377 - val_loss: 0.3868 - val_acc: 0.8235\n",
      "Epoch 369/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3216 - acc: 0.8482 - val_loss: 0.3776 - val_acc: 0.8529\n",
      "Epoch 370/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3302 - acc: 0.8586 - val_loss: 0.3626 - val_acc: 0.8529\n",
      "Epoch 371/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3274 - acc: 0.8482 - val_loss: 0.3525 - val_acc: 0.8529\n",
      "Epoch 372/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3210 - acc: 0.8796 - val_loss: 0.3459 - val_acc: 0.8529\n",
      "Epoch 373/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2877 - acc: 0.8796 - val_loss: 0.3476 - val_acc: 0.9118\n",
      "Epoch 374/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3111 - acc: 0.8429 - val_loss: 0.3480 - val_acc: 0.8529\n",
      "Epoch 375/500\n",
      "191/191 [==============================] - 0s 74us/step - loss: 0.3255 - acc: 0.8639 - val_loss: 0.3457 - val_acc: 0.8529\n",
      "Epoch 376/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3754 - acc: 0.8272 - val_loss: 0.3553 - val_acc: 0.8824\n",
      "Epoch 377/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3241 - acc: 0.8534 - val_loss: 0.3629 - val_acc: 0.8824\n",
      "Epoch 378/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.2889 - acc: 0.8953 - val_loss: 0.3734 - val_acc: 0.8529\n",
      "Epoch 379/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3189 - acc: 0.8743 - val_loss: 0.3670 - val_acc: 0.8824\n",
      "Epoch 380/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3287 - acc: 0.8534 - val_loss: 0.3638 - val_acc: 0.8529\n",
      "Epoch 381/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3074 - acc: 0.8743 - val_loss: 0.3623 - val_acc: 0.8529\n",
      "Epoch 382/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.3360 - acc: 0.8272 - val_loss: 0.3614 - val_acc: 0.8529\n",
      "Epoch 383/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3469 - acc: 0.8377 - val_loss: 0.3569 - val_acc: 0.8529\n",
      "Epoch 384/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3496 - acc: 0.8534 - val_loss: 0.3537 - val_acc: 0.8529\n",
      "Epoch 385/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.3073 - acc: 0.8691 - val_loss: 0.3492 - val_acc: 0.8529\n",
      "Epoch 386/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2933 - acc: 0.8743 - val_loss: 0.3497 - val_acc: 0.8529\n",
      "Epoch 387/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2983 - acc: 0.8639 - val_loss: 0.3590 - val_acc: 0.8529\n",
      "Epoch 388/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2943 - acc: 0.8848 - val_loss: 0.3655 - val_acc: 0.8529\n",
      "Epoch 389/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3156 - acc: 0.8482 - val_loss: 0.3666 - val_acc: 0.8824\n",
      "Epoch 390/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2949 - acc: 0.8848 - val_loss: 0.3782 - val_acc: 0.8824\n",
      "Epoch 391/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3304 - acc: 0.8691 - val_loss: 0.3835 - val_acc: 0.8529\n",
      "Epoch 392/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3071 - acc: 0.8534 - val_loss: 0.3788 - val_acc: 0.8529\n",
      "Epoch 393/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3047 - acc: 0.8586 - val_loss: 0.3766 - val_acc: 0.8529\n",
      "Epoch 394/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3163 - acc: 0.8796 - val_loss: 0.3743 - val_acc: 0.8529\n",
      "Epoch 395/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3217 - acc: 0.8796 - val_loss: 0.3648 - val_acc: 0.8529\n",
      "Epoch 396/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2913 - acc: 0.8796 - val_loss: 0.3582 - val_acc: 0.8235\n",
      "Epoch 397/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3330 - acc: 0.8534 - val_loss: 0.3628 - val_acc: 0.8529\n",
      "Epoch 398/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3139 - acc: 0.8534 - val_loss: 0.3702 - val_acc: 0.8529\n",
      "Epoch 399/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3213 - acc: 0.8586 - val_loss: 0.3735 - val_acc: 0.8824\n",
      "Epoch 400/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2940 - acc: 0.8691 - val_loss: 0.3866 - val_acc: 0.8529\n",
      "Epoch 401/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2899 - acc: 0.8586 - val_loss: 0.3876 - val_acc: 0.8529\n",
      "Epoch 402/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2841 - acc: 0.8639 - val_loss: 0.3707 - val_acc: 0.8235\n",
      "Epoch 403/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2725 - acc: 0.8796 - val_loss: 0.3679 - val_acc: 0.8235\n",
      "Epoch 404/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3238 - acc: 0.8796 - val_loss: 0.3870 - val_acc: 0.8529\n",
      "Epoch 405/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3329 - acc: 0.8639 - val_loss: 0.3675 - val_acc: 0.7941\n",
      "Epoch 406/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3001 - acc: 0.8953 - val_loss: 0.3707 - val_acc: 0.8529\n",
      "Epoch 407/500\n",
      "191/191 [==============================] - 0s 100us/step - loss: 0.2953 - acc: 0.8796 - val_loss: 0.3721 - val_acc: 0.7941\n",
      "Epoch 408/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2933 - acc: 0.8848 - val_loss: 0.3754 - val_acc: 0.8529\n",
      "Epoch 409/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2820 - acc: 0.8482 - val_loss: 0.3818 - val_acc: 0.8529\n",
      "Epoch 410/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2924 - acc: 0.8639 - val_loss: 0.3771 - val_acc: 0.8235\n",
      "Epoch 411/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.3075 - acc: 0.8325 - val_loss: 0.3709 - val_acc: 0.8529\n",
      "Epoch 412/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2671 - acc: 0.8848 - val_loss: 0.3683 - val_acc: 0.8235\n",
      "Epoch 413/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2914 - acc: 0.8743 - val_loss: 0.3654 - val_acc: 0.8235\n",
      "Epoch 414/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2603 - acc: 0.8848 - val_loss: 0.3639 - val_acc: 0.8235\n",
      "Epoch 415/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3225 - acc: 0.8482 - val_loss: 0.3674 - val_acc: 0.7941\n",
      "Epoch 416/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3155 - acc: 0.8639 - val_loss: 0.3759 - val_acc: 0.7941\n",
      "Epoch 417/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2997 - acc: 0.8482 - val_loss: 0.3913 - val_acc: 0.8529\n",
      "Epoch 418/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2803 - acc: 0.9058 - val_loss: 0.4226 - val_acc: 0.8529\n",
      "Epoch 419/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3604 - acc: 0.8586 - val_loss: 0.4057 - val_acc: 0.8235\n",
      "Epoch 420/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3217 - acc: 0.8691 - val_loss: 0.3918 - val_acc: 0.8235\n",
      "Epoch 421/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2927 - acc: 0.8796 - val_loss: 0.3901 - val_acc: 0.8529\n",
      "Epoch 422/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2876 - acc: 0.8743 - val_loss: 0.3706 - val_acc: 0.8529\n",
      "Epoch 423/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3307 - acc: 0.8429 - val_loss: 0.3626 - val_acc: 0.7941\n",
      "Epoch 424/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3211 - acc: 0.8691 - val_loss: 0.3626 - val_acc: 0.8529\n",
      "Epoch 425/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2731 - acc: 0.8743 - val_loss: 0.3791 - val_acc: 0.8529\n",
      "Epoch 426/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2765 - acc: 0.9005 - val_loss: 0.3720 - val_acc: 0.8529\n",
      "Epoch 427/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.3045 - acc: 0.8796 - val_loss: 0.3890 - val_acc: 0.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2554 - acc: 0.8848 - val_loss: 0.4052 - val_acc: 0.8235\n",
      "Epoch 429/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3097 - acc: 0.8691 - val_loss: 0.4111 - val_acc: 0.8235\n",
      "Epoch 430/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2859 - acc: 0.8848 - val_loss: 0.4033 - val_acc: 0.8235\n",
      "Epoch 431/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3378 - acc: 0.8639 - val_loss: 0.4220 - val_acc: 0.7941\n",
      "Epoch 432/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2971 - acc: 0.8743 - val_loss: 0.3788 - val_acc: 0.8235\n",
      "Epoch 433/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2974 - acc: 0.8482 - val_loss: 0.3867 - val_acc: 0.8529\n",
      "Epoch 434/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2905 - acc: 0.8534 - val_loss: 0.3769 - val_acc: 0.8529\n",
      "Epoch 435/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2775 - acc: 0.8691 - val_loss: 0.4193 - val_acc: 0.8235\n",
      "Epoch 436/500\n",
      "191/191 [==============================] - 0s 89us/step - loss: 0.3230 - acc: 0.8377 - val_loss: 0.3767 - val_acc: 0.8529\n",
      "Epoch 437/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2775 - acc: 0.8848 - val_loss: 0.3940 - val_acc: 0.7941\n",
      "Epoch 438/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3428 - acc: 0.8639 - val_loss: 0.3974 - val_acc: 0.8235\n",
      "Epoch 439/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2843 - acc: 0.8534 - val_loss: 0.4133 - val_acc: 0.8235\n",
      "Epoch 440/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2740 - acc: 0.8534 - val_loss: 0.3930 - val_acc: 0.8235\n",
      "Epoch 441/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2980 - acc: 0.8901 - val_loss: 0.3866 - val_acc: 0.8235\n",
      "Epoch 442/500\n",
      "191/191 [==============================] - 0s 84us/step - loss: 0.3501 - acc: 0.8534 - val_loss: 0.4019 - val_acc: 0.8235\n",
      "Epoch 443/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3014 - acc: 0.8639 - val_loss: 0.3645 - val_acc: 0.8235\n",
      "Epoch 444/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3067 - acc: 0.8691 - val_loss: 0.3623 - val_acc: 0.8235\n",
      "Epoch 445/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2900 - acc: 0.8586 - val_loss: 0.3607 - val_acc: 0.8235\n",
      "Epoch 446/500\n",
      "191/191 [==============================] - 0s 89us/step - loss: 0.3060 - acc: 0.8639 - val_loss: 0.3761 - val_acc: 0.8529\n",
      "Epoch 447/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2799 - acc: 0.8743 - val_loss: 0.3778 - val_acc: 0.8529\n",
      "Epoch 448/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.3017 - acc: 0.8534 - val_loss: 0.3780 - val_acc: 0.8529\n",
      "Epoch 449/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.3075 - acc: 0.8743 - val_loss: 0.3777 - val_acc: 0.8529\n",
      "Epoch 450/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.3118 - acc: 0.8639 - val_loss: 0.3937 - val_acc: 0.8529\n",
      "Epoch 451/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2784 - acc: 0.8743 - val_loss: 0.3752 - val_acc: 0.8235\n",
      "Epoch 452/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2659 - acc: 0.9005 - val_loss: 0.3807 - val_acc: 0.8235\n",
      "Epoch 453/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3172 - acc: 0.8796 - val_loss: 0.3848 - val_acc: 0.8235\n",
      "Epoch 454/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3083 - acc: 0.8796 - val_loss: 0.3927 - val_acc: 0.8529\n",
      "Epoch 455/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2639 - acc: 0.8848 - val_loss: 0.3786 - val_acc: 0.8235\n",
      "Epoch 456/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2655 - acc: 0.9110 - val_loss: 0.3785 - val_acc: 0.8235\n",
      "Epoch 457/500\n",
      "191/191 [==============================] - 0s 79us/step - loss: 0.2637 - acc: 0.9005 - val_loss: 0.3830 - val_acc: 0.8529\n",
      "Epoch 458/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3186 - acc: 0.8743 - val_loss: 0.3810 - val_acc: 0.8529\n",
      "Epoch 459/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.3027 - acc: 0.8848 - val_loss: 0.3806 - val_acc: 0.8235\n",
      "Epoch 460/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.2473 - acc: 0.9058 - val_loss: 0.3882 - val_acc: 0.8529\n",
      "Epoch 461/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.3022 - acc: 0.8586 - val_loss: 0.3796 - val_acc: 0.8235\n",
      "Epoch 462/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2793 - acc: 0.8953 - val_loss: 0.3728 - val_acc: 0.8235\n",
      "Epoch 463/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3156 - acc: 0.8639 - val_loss: 0.3959 - val_acc: 0.8529\n",
      "Epoch 464/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2948 - acc: 0.8796 - val_loss: 0.4066 - val_acc: 0.8235\n",
      "Epoch 465/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2557 - acc: 0.9058 - val_loss: 0.3904 - val_acc: 0.8529\n",
      "Epoch 466/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2466 - acc: 0.9005 - val_loss: 0.3910 - val_acc: 0.8235\n",
      "Epoch 467/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2770 - acc: 0.9005 - val_loss: 0.3960 - val_acc: 0.8529\n",
      "Epoch 468/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2860 - acc: 0.8848 - val_loss: 0.4006 - val_acc: 0.8529\n",
      "Epoch 469/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.3138 - acc: 0.8586 - val_loss: 0.3768 - val_acc: 0.8235\n",
      "Epoch 470/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2652 - acc: 0.8953 - val_loss: 0.3772 - val_acc: 0.7941\n",
      "Epoch 471/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2636 - acc: 0.8901 - val_loss: 0.3733 - val_acc: 0.8235\n",
      "Epoch 472/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2903 - acc: 0.8691 - val_loss: 0.3904 - val_acc: 0.8529\n",
      "Epoch 473/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2646 - acc: 0.8901 - val_loss: 0.3950 - val_acc: 0.8235\n",
      "Epoch 474/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2639 - acc: 0.8796 - val_loss: 0.3896 - val_acc: 0.8235\n",
      "Epoch 475/500\n",
      "191/191 [==============================] - 0s 79us/step - loss: 0.2656 - acc: 0.8953 - val_loss: 0.3960 - val_acc: 0.8235\n",
      "Epoch 476/500\n",
      "191/191 [==============================] - 0s 68us/step - loss: 0.2746 - acc: 0.8901 - val_loss: 0.4084 - val_acc: 0.8235\n",
      "Epoch 477/500\n",
      "191/191 [==============================] - 0s 53us/step - loss: 0.2756 - acc: 0.9005 - val_loss: 0.4141 - val_acc: 0.8235\n",
      "Epoch 478/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2864 - acc: 0.8534 - val_loss: 0.3819 - val_acc: 0.8235\n",
      "Epoch 479/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.2643 - acc: 0.8848 - val_loss: 0.3728 - val_acc: 0.8235\n",
      "Epoch 480/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2718 - acc: 0.9162 - val_loss: 0.4052 - val_acc: 0.8529\n",
      "Epoch 481/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2809 - acc: 0.8639 - val_loss: 0.3751 - val_acc: 0.8529\n",
      "Epoch 482/500\n",
      "191/191 [==============================] - 0s 58us/step - loss: 0.2572 - acc: 0.8796 - val_loss: 0.3762 - val_acc: 0.7941\n",
      "Epoch 483/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2697 - acc: 0.8848 - val_loss: 0.4046 - val_acc: 0.8529\n",
      "Epoch 484/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2821 - acc: 0.8743 - val_loss: 0.3993 - val_acc: 0.8235\n",
      "Epoch 485/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2538 - acc: 0.8901 - val_loss: 0.3937 - val_acc: 0.7941\n",
      "Epoch 486/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.3191 - acc: 0.8848 - val_loss: 0.3973 - val_acc: 0.8235\n",
      "Epoch 487/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2867 - acc: 0.8796 - val_loss: 0.4089 - val_acc: 0.8529\n",
      "Epoch 488/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2493 - acc: 0.9005 - val_loss: 0.3912 - val_acc: 0.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2652 - acc: 0.9058 - val_loss: 0.3814 - val_acc: 0.8235\n",
      "Epoch 490/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2277 - acc: 0.9058 - val_loss: 0.3819 - val_acc: 0.8235\n",
      "Epoch 491/500\n",
      "191/191 [==============================] - 0s 31us/step - loss: 0.2905 - acc: 0.8743 - val_loss: 0.3961 - val_acc: 0.8529\n",
      "Epoch 492/500\n",
      "191/191 [==============================] - 0s 32us/step - loss: 0.2765 - acc: 0.8953 - val_loss: 0.3932 - val_acc: 0.8529\n",
      "Epoch 493/500\n",
      "191/191 [==============================] - 0s 63us/step - loss: 0.2438 - acc: 0.8796 - val_loss: 0.3914 - val_acc: 0.8235\n",
      "Epoch 494/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2379 - acc: 0.8848 - val_loss: 0.4094 - val_acc: 0.8529\n",
      "Epoch 495/500\n",
      "191/191 [==============================] - 0s 47us/step - loss: 0.2972 - acc: 0.8848 - val_loss: 0.3875 - val_acc: 0.8235\n",
      "Epoch 496/500\n",
      "191/191 [==============================] - 0s 37us/step - loss: 0.2417 - acc: 0.9110 - val_loss: 0.3800 - val_acc: 0.8235\n",
      "Epoch 497/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2667 - acc: 0.8848 - val_loss: 0.4084 - val_acc: 0.8529\n",
      "Epoch 498/500\n",
      "191/191 [==============================] - 0s 73us/step - loss: 0.2855 - acc: 0.8534 - val_loss: 0.3823 - val_acc: 0.8529\n",
      "Epoch 499/500\n",
      "191/191 [==============================] - 0s 42us/step - loss: 0.2788 - acc: 0.8953 - val_loss: 0.3783 - val_acc: 0.7941\n",
      "Epoch 500/500\n",
      "191/191 [==============================] - 0s 52us/step - loss: 0.2885 - acc: 0.8743 - val_loss: 0.3987 - val_acc: 0.8529\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=500,\n",
    "                    validation_split=0.15,\n",
    "                    batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24479eb4828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'training loss')\n",
    "plt.plot(history.history['val_loss'], label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuMH1UGePmioAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2447867bd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label = 'training accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 67us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2477021142674817, 0.89333333333333331]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 193us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47791945725156548, 0.87719297095348958]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
